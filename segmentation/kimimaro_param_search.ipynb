{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing parameters for Kimimaro skeletonization. \n",
    "#### Objectives:\n",
    " ##### 1. Download a skeleton from CV\n",
    " ##### 2. Choose a random point on the skeleton.\n",
    " ##### 3. Download a 256 pixel cube surrounding the point.\n",
    " ##### 4. Run kimimaro with some parameter set.\n",
    " ##### 5. Select the ground truth nodes corresponding to the 256 pixel bounding box.\n",
    " ##### 6. Calculate the similarity between the new skeleton and the ground truth skeleton\n",
    " ##### 7. Repeat across parameter space, and across the skeleton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cloudvolume import Bbox, Vec, CloudVolume, volumecutout, view\n",
    "import kimimaro\n",
    "from meshparty import trimesh_io, trimesh_vtk, skeleton_io\n",
    "import navis\n",
    "import pymaid\n",
    "import numpy as np\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from matplotlib import pyplot as plt\n",
    "import random\n",
    "from scipy import spatial\n",
    "import math\n",
    "\n",
    "if '/Users/brandon/Documents/Repositories/Python/FANC_auto_recon/transforms/' not in sys.path:\n",
    "    sys.path.append('/Users/brandon/Documents/Repositories/Python/FANC_auto_recon/transforms/')\n",
    "\n",
    "\n",
    "from fanc_seg_utils import neuroglancer_utilities\n",
    "from fanc_seg_utils import catmaid_utilities\n",
    "from fanc_seg_utils import skeletonization\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establish connections\n",
    "instance = catmaid_utilities.catmaid_login('fanc',60,'/Users/brandon/Documents/MN_Analysis/catmaid_keys.txt')\n",
    "cv = CloudVolume('https://storage.googleapis.com/zetta_lee_fly_vnc_001_segmentation/vnc1_full_v3align_2/realigned_v1/seg/full_run_v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_vertex(skeleton):\n",
    "    ''' Pick a random vertex from a skeleton\n",
    "    Args:\n",
    "        skeleton: cv skeleton object\n",
    "    Returns:\n",
    "        coordinates of a skeleton node'''\n",
    "    return(sk.vertices[random.randint(0,len(sk.vertices))])\n",
    "\n",
    "def download_vol(pt, size=256, seg_mip = np.array([17.2,17.2,45])):\n",
    "    ''' Download segmentation cube\n",
    "    Args:\n",
    "        pt: np.array, mip0 xyz coord at center\n",
    "        size: int, size in pixels of cube to download\n",
    "        seg_mip: np.array, resolution of segmentation\n",
    "    Returns:\n",
    "        segmentation cube'''\n",
    "    img_vol = cv.download_point(pt // np.array([4, 4, 1]) ,size=512, mip = seg_mip)\n",
    "    return(img_vol)\n",
    "\n",
    "def return_bounds(img_vol,transform = True):\n",
    "    ''' Return bbox for image volume\n",
    "    Args:\n",
    "        img_vol: cv cutout\n",
    "        transform: bool, default is true. We want to transform the points of the bbox to generate a filter for a catmaid skeleton which is in fanc3 space.\n",
    "    Returns:\n",
    "        bbox as np.array [[xmin,xmax],[ymin,ymax],[zmin,zmax]] in voxel coords'''\\\n",
    "    \n",
    "    bbox = img_vol.bounds.to_list() * np.array([4,4,1,4,4,1])\n",
    "    if transform is True:\n",
    "        bbox = neuroglancer_utilities.fanc4_to_3(bbox.reshape(2,3).astype('float64'))\n",
    " \n",
    "    return([bbox['x']*np.array([4.3,4.3]),bbox['y']*np.array([4.3,4.3]),bbox['z']*np.array([45,45])])\n",
    "\n",
    "def bbox_filter(points, bbox):\n",
    "    ''' Return skeleton coords within a bbox\n",
    "    Args:\n",
    "        points: np.array, nx3 array of mip0 vertex coords to filter\n",
    "        bbox: list, bbox as returned from return_bounds to filter coordinates\n",
    "    Returns:\n",
    "        vertex coordinates within bounding box'''\n",
    "    \n",
    "    bound_x = np.logical_and(points[:, 0] > bbox[0][0], points[:, 0] < bbox[0][1])\n",
    "    bound_y = np.logical_and(points[:, 1] > bbox[1][0], points[:, 1] < bbox[1][1])\n",
    "    bound_z = np.logical_and(points[:, 2] > bbox[2][0], points[:, 2] < bbox[2][1])\n",
    "\n",
    "    bbox_mask = np.logical_and(np.logical_and(bound_x, bound_y), bound_z)\n",
    "\n",
    "    return points[bbox_mask]\n",
    "\n",
    "def transform_pts(skeleton, img_res = np.array([4.3,4.3,45])):\n",
    "    ''' Transform to CATMAID space\n",
    "    args: \n",
    "        skeleton: cv skeleton ovject with voxel coord vertices\n",
    "        img_res: np.array, NG resolution\n",
    "    returns:\n",
    "        cv skeleton object with transformed vertices in voxel coordinates'''\n",
    "    tf = neuroglancer_utilities.fanc4_to_3(skeleton.vertices / img_res)\n",
    "    skeleton.vertices = np.array(list(zip(tf['x'],tf['y'],tf['z'])))\n",
    "    skeleton.vertices = skeleton.vertices * img_res\n",
    "    return(skeleton)\n",
    "    \n",
    "    \n",
    "def skeletonize(image_vol,seg_id,img_res,**kwargs):\n",
    "    ''' Run skeletonization on the seg_id of interest. Use kwargs to vary params'''\n",
    "    \n",
    "    teasar_params={\n",
    "    'scale': 1,\n",
    "    'const': 200, # physical units\n",
    "    'pdrf_exponent': 4,\n",
    "    'pdrf_scale': 100000,\n",
    "    'soma_detection_threshold': 1100, # physical units\n",
    "    'soma_acceptance_threshold': 3500, # physical units\n",
    "    'soma_invalidation_scale': 1.0,\n",
    "    'soma_invalidation_const': 300, # physical units\n",
    "    'max_paths': None, # default None\n",
    "  }\n",
    "    for i in teasar_params.keys():\n",
    "        if i in kwargs.keys():\n",
    "            teasar_params[i] = kwargs[i]\n",
    "    \n",
    "    if 'dust_threshold' in kwargs.keys():\n",
    "        dust_threshold = kwargs['dust_threshold']\n",
    "    else:\n",
    "        dust_threshold = 500\n",
    "        \n",
    "        \n",
    "    skels = kimimaro.skeletonize(\n",
    "      image_vol,teasar_params=teasar_params,\n",
    "      object_ids=[seg_id], # process only the specified labels\n",
    "      # extra_targets_before=[ (27,33,100), (44,45,46) ], # target points in voxels\n",
    "      # extra_targets_after=[ (27,33,100), (44,45,46) ], # target points in voxels\n",
    "      dust_threshold = dust_threshold, # skip connected components with fewer than this many voxels\n",
    "      anisotropy=(17,17,45), # default True\n",
    "      fix_branching=True, # default True\n",
    "      fix_borders=True, # default True\n",
    "      fill_holes=True, # default False\n",
    "      fix_avocados=True, # default False\n",
    "      progress=True, # default False, show progress bar\n",
    "      parallel=0, # <= 0 all cpu, 1 single process, 2+ multiprocess\n",
    "      parallel_chunk_size=100, # how many skeletons to process before updating progress bar\n",
    "    )\n",
    "    \n",
    "    for i in kwargs.keys():\n",
    "        param = i\n",
    "        val = kwargs[i]\n",
    "        print(val)\n",
    "    \n",
    "\n",
    "    for i in skels.keys():\n",
    "        sk = skels[i]\n",
    "        sk.vertices =  (sk.vertices) + (np.array(image_vol.bounds.to_list()[0:3]) * np.array([4,4,1])) * img_res\n",
    "        transform_pts(sk)\n",
    "      \n",
    "\n",
    "    \n",
    "    return(skels[seg_id])    \n",
    "\n",
    "\n",
    "def measure_similarity(a, b, sigma=2000, omega=4000):\n",
    "\n",
    "    # Get distance matrix\n",
    "    dist_mat = spatial.distance.cdist(a, b)\n",
    "\n",
    "    # Get index of closest nodes in ground_truth\n",
    "    closest_ix = np.argmin(dist_mat, axis=1)\n",
    "\n",
    "    # Get closest distances\n",
    "    closest_dist = dist_mat.min(axis=1)\n",
    "\n",
    "    # Get intra-neuron matrices \n",
    "    distA = spatial.distance.pdist(a)\n",
    "    distA = spatial.distance.squareform(distA)\n",
    "    distB = spatial.distance.pdist(b)\n",
    "    distB = spatial.distance.squareform(distB)\n",
    "\n",
    "    # Calculate number of nodes closer than OMEGA. \n",
    "    closeA = (distA <= omega).sum(axis=1)\n",
    "    closeB = (distB <= omega).sum(axis=1)\n",
    "\n",
    "    # Calculate the scores over all nodes\n",
    "    all_values = []\n",
    "    for a in range(distA.shape[0]):\n",
    "        this_synapse_value = math.exp(-1 * math.fabs(closeA[a] - closeB[closest_ix[a]]) / (\n",
    "            closeA[a] + closeB[closest_ix[a]])) * math.exp(-1 * (closest_dist[a]**2) / (2 * sigma**2))\n",
    "        all_values.append(this_synapse_value)\n",
    "\n",
    "    score = sum(all_values) / len(all_values)\n",
    "\n",
    "    return score\n",
    "\n",
    "def compare_against_ground_truth(new,ground_truth):\n",
    "    forward = measure_similarity(new,ground_truth)\n",
    "    reverse = measure_similarity(ground_truth,new)\n",
    "    return((forward+reverse)/2)\n",
    "\n",
    "def find_min_dist(new_skeleton,ground_truth):\n",
    "    distances = spatial.distance.cdist(new_skeleton,ground_truth)\n",
    "    min_dist = np.mean(distances.min(axis=0)**2)\n",
    "    \n",
    "    return(min_dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Parameter Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_space = {'scale':range(1,4),\n",
    "              'const': range(250,750,50),\n",
    "              'pdrf_exponent': range(1,7),\n",
    "              'pdrf_scale': range(10000,100000,5000)}\n",
    "\n",
    "params = []\n",
    "for s in param_space['scale']:\n",
    "    for c in param_space['const']:\n",
    "        for ex in param_space['pdrf_exponent']:\n",
    "            for sc in param_space['pdrf_scale']:\n",
    "                params.append({'scale':s,'const':c,'pdrf_exponent':ex,'pdrf_scale':sc})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download skeleton from cloud_volume. Get bounding box.\n",
    "img_res = np.array([4.3,4.3,45])\n",
    "seg_id = 74172093612626737\n",
    "sk = cv.skeleton.get(seg_id)\n",
    "sk.vertices = sk.vertices / img_res\n",
    "\n",
    "## Download test neuron from CATMAID, get nodes within box to compare\n",
    "n = pymaid.get_neurons('annotations:FANC4_ID: 74172093612626737',remote_instance=instance)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sims = []\n",
    "all_ranks = []\n",
    "all_fragments = []\n",
    "for j in range(5):\n",
    "    img_vol = download_vol(choose_vertex(sk))\n",
    "    sims = []\n",
    "    neuron_fragments = []\n",
    "\n",
    "    for i in range(1,1000,200):\n",
    "        new_neuron = skeletonize(img_vol,seg_id,img_res,**params[i])\n",
    "        bbox = return_bounds(img_vol)\n",
    "        nodes_to_compare = bbox_filter(n.nodes[['x','y','z']].values,bbox)\n",
    "        sims.append(find_min_dist(new_neuron.vertices,nodes_to_compare))\n",
    "        neuron_fragments.append(new_neuron)\n",
    "\n",
    "    temp = np.array(sims).argsort()\n",
    "    ranks = np.empty_like(temp)\n",
    "    ranks[temp] = np.arange(len(sims))\n",
    "    all_ranks.append(ranks)\n",
    "    all_sims.append(sims/np.max(sims))\n",
    "    all_fragments.append(neuron_fragments)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(n.nodes['x'],n.nodes['z'],c='r')\n",
    "plt.scatter(new_neuron.vertices[:,0],new_neuron.vertices[:,2],alpha=.05)\n",
    "plt.xlim(left=bbox[0][0],right=bbox[0][1])\n",
    "plt.ylim(top=bbox[2][0],bottom=bbox[2][1])\n",
    "measure_similarity(new_neuron.vertices,nodes_to_compare)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detect Somas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soma_params = {'soma_detection_threshold': 2000, # physical units\n",
    "    'soma_acceptance_threshold': 5500, # physical units\n",
    "    'soma_invalidation_scale': 1.0,\n",
    "    'soma_invalidation_const': 800} # physical units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_vol = download_vol(np.array([62944, 114880, 2300]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_neuron = skeletonize(img_vol,seg_id,img_res,**soma_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(range(10000,100000,5000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "connectomics_analysis",
   "language": "python",
   "name": "connectomics_analysis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
