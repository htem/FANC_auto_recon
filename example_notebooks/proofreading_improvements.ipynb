{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Improving proofreading interface\n",
    "1. Render skeleton points\n",
    "2. Make largest fragment red\n",
    "2. Make all others a color range based on size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/Users/brandon/Documents/Repositories/Python/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from FANC_auto_recon.segmentation import authentication_utils,rootID_lookup\n",
    "from FANC_auto_recon.proofreading import proofreading_utils\n",
    "from FANC_auto_recon.connectomics_bot import response_methods\n",
    "from FANC_auto_recon.skeletonization import catmaid_utilities\n",
    "import pymaid\n",
    "from cloudvolume import CloudVolume\n",
    "from nglui.statebuilder import *\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from FANC_auto_recon.transforms import realignment\n",
    "import json\n",
    "from matplotlib import cm\n",
    "from matplotlib import colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def skel2seg(skid, project=13, segment_threshold = 10, node_threshold = None):\n",
    "    \n",
    "    CI = catmaid_utilities.catmaid_login('FANC',project)\n",
    "    try:\n",
    "        n = pymaid.get_neurons(skid)\n",
    "    except:\n",
    "        return('No matching skeleton ID in project {}'.format(project))\n",
    "    \n",
    "    n.downsample(inplace=True)\n",
    "\n",
    "    nodes = n.nodes[['x','y','z']].values/ np.array([4.3,4.3,45])\n",
    "    skeleton_nodes_voxel = realignment.fanc3_to_4(nodes, verbose=False)\n",
    "\n",
    "    target_volume = CloudVolume(authentication_utils.get_cv_path('FANC_production_segmentation')['url'], use_https=True, agglomerate=False)\n",
    "    transformed = realignment.fanc3_to_4(skeleton_nodes_voxel)\n",
    "\n",
    "    seg_ids = rootID_lookup.segIDs_from_pts(target_volume,transformed)\n",
    "    \n",
    "    neuron_df,skeleton_df = fragment_dataframes(seg_ids,\n",
    "                                     transformed,\n",
    "                                     segment_threshold=segment_threshold,\n",
    "                                     node_threshold=node_threshold)\n",
    "    annotations = [{'name':'skeleton coords',\n",
    "                'type':'points',\n",
    "                'data': skeleton_df}]\n",
    "    return render_scene(neurons=neuron_df,annotations=annotations,return_as='url')\n",
    " \n",
    "    \n",
    "def fragment_dataframes(seg_ids,coords,segment_threshold=None,node_threshold=20):\n",
    "\n",
    "    ids,counts = np.unique(seg_ids,return_counts=True)\n",
    "    value_counts = np.array(list(zip(ids,counts)),dtype=int)\n",
    "    value_counts=value_counts[value_counts[:,0]!=0,:]\n",
    "\n",
    "    primary_neuron = value_counts[value_counts[:,1]==max(value_counts[:,1]),0]\n",
    "    fragments = value_counts[value_counts[:,0]!=primary_neuron,:]\n",
    "\n",
    "    if segment_threshold and not node_threshold:\n",
    "        ids_to_use = fragments[np.argsort(-fragments[:,1])[0:segment_threshold],0]\n",
    "    elif node_threshold and not segment_threshold:\n",
    "        ids_to_use = fragments[fragments[:,1]>node_threshold][:,0]\n",
    "    elif node_threshold and segment_threshold:\n",
    "        print('Warning: cannot use segment and node threshold concurrently,defaulting to segment threshold')\n",
    "        ids_to_use = fragments[np.argsort(-fragments[:,1])]\n",
    "    else:\n",
    "        ids_to_use = seg_ids\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "    skeleton_df = pd.DataFrame(columns=['segment_id','xyz'])\n",
    "    skeleton_df.xyz = [i for i in coords]\n",
    "    cmap = cm.get_cmap('viridis', len(ids_to_use)) \n",
    "    sk_colors = [colors.rgb2hex(cmap(i)) for i in range(cmap.N)]\n",
    "    \n",
    "    \n",
    "    neuron_df = pd.DataFrame(columns=['segment_id','xyz','color'])\n",
    "    neuron_df.segment_id = ids_to_use\n",
    "    \n",
    "    j = 0\n",
    "    for i in ids_to_use:\n",
    "        idx = seg_ids == i\n",
    "        neuron_df.loc[neuron_df.segment_id ==i,'color'] = sk_colors[j]\n",
    "        j+=1\n",
    "\n",
    "    neuron_df = neuron_df.append({'segment_id':primary_neuron[0],'xyz':None,'color':\"#ff0000\"},ignore_index=True)\n",
    "    return neuron_df,skeleton_df\n",
    "\n",
    "def render_scene(neurons = None,\n",
    "                 img_source = None,\n",
    "                 seg_source = None,\n",
    "                 state_server=None,\n",
    "                 annotations = None,\n",
    "                 client=None,\n",
    "                 return_as = 'url'):\n",
    "                \n",
    "    \n",
    "    if client is None:\n",
    "        client,token = authentication_utils.get_client()\n",
    "\n",
    "\n",
    "    if neurons is None:\n",
    "        neurons = pd.DataFrame(columns=['segment_id','xyz','color'])\n",
    "    elif isinstance(neurons,list):\n",
    "        \n",
    "        cmap = cm.get_cmap('Set1', len(neurons)) \n",
    "        neurons_df = pd.DataFrame(columns=['segment_id','xyz','color'])\n",
    "        neurons_df['segment_id'] = neurons\n",
    "        neurons_df['color'] = [colors.rgb2hex(cmap(i)) for i in range(cmap.N)]\n",
    "\n",
    "    \n",
    "\n",
    "    paths = authentication_utils.get_cv_path()\n",
    "\n",
    "    if img_source is None:\n",
    "        img_source = paths['Image']['url']\n",
    "    if seg_source is None:\n",
    "        seg_source = paths['FANC_production_segmentation']['url']\n",
    "    if state_server is None:\n",
    "        state_server = paths['json_server']['url']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # Set layer segmentation layer\n",
    "    img_layer = ImageLayerConfig(img_source,name='FANCv4')\n",
    "\n",
    "\n",
    "    seg_layer = SegmentationLayerConfig(name = 'seg_Mar2021_proofreading',\n",
    "                                   source = seg_source,\n",
    "                                   selected_ids_column='segment_id',\n",
    "                                   color_column= 'color',\n",
    "                                   fixed_ids= None,\n",
    "                                   active = False)\n",
    "\n",
    "\n",
    "    standard_state = StateBuilder(layers=[img_layer,seg_layer],resolution=[4.3,4.3,45])\n",
    "\n",
    "\n",
    "\n",
    "    # Data Layer(s)\n",
    "\n",
    "    annotation_states = []\n",
    "    annotation_data = []\n",
    "    if annotations is not None:\n",
    "        for i in annotations:\n",
    "\n",
    "            if i['type'] is 'points':\n",
    "                anno_mapper = PointMapper(point_column='xyz')  \n",
    "   \n",
    "            anno_layer =  AnnotationLayerConfig(name=i['name'],mapping_rules=anno_mapper)\n",
    "\n",
    "            annotation_states.append(StateBuilder(layers=[anno_layer],resolution=[4.3,4.3,45]))\n",
    "            annotation_data.append(i['data'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    chained_sb = ChainedStateBuilder([standard_state]+annotation_states)\n",
    "    state = json.loads(chained_sb.render_state([neurons]+annotation_data, return_as='json'))\n",
    "\n",
    "    # Add brain regions\n",
    "    state['layers'].append( {\"type\": \"segmentation\",\n",
    "          \"mesh\": paths['volumes']['url'],\n",
    "          \"objectAlpha\": 0.1,\n",
    "          \"hideSegmentZero\": False,\n",
    "          \"ignoreSegmentInteractions\": True,\n",
    "          \"segmentColors\": {\n",
    "            \"1\": \"#bfbfbf\",\n",
    "            \"2\": \"#d343d6\"\n",
    "          },\n",
    "          \"segments\": [\n",
    "            \"1\",\n",
    "            \"2\"\n",
    "          ],\n",
    "          \"skeletonRendering\": {\n",
    "            \"mode2d\": \"lines_and_points\",\n",
    "            \"mode3d\": \"lines\"\n",
    "          },\n",
    "          \"name\": \"volume outlines\"\n",
    "        })\n",
    "\n",
    "    if return_as is 'url':\n",
    "        return(paths['neuroglancer_base']['url'] + '?json_url={path}{state_id}'.format(path=paths['json_server']['url'],\n",
    "                                                                                       state_id=client.state.upload_state_json(state)))\n",
    "    else:\n",
    "        return(state)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO  : Global CATMAID instance set. Caching is ON. (pymaid)\n",
      "Segmentation IDs: 100%|██████████| 768/768 [01:52<00:00,  6.80it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'https://neuromancer-seung-import.appspot.com/?json_url=https://api.zetta.ai/json/601987990957767144'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skid = 694501\n",
    "project = 13\n",
    "\n",
    "skel2seg(skid,project)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "connectomics_analysis",
   "language": "python",
   "name": "connectomics_analysis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
