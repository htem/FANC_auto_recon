{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# cellbody2neuron\n",
    "Using Jasper's idea to predict parent neurons for nuclei, Thank you so much, Jasper."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "# https://www.j-focus.jp/user_guide/ug0004040000/\n",
    "# sbatch"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# libraries 1\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import argparse\n",
    "\n",
    "from cloudvolume import CloudVolume, view, Bbox\n",
    "import fill_voids\n",
    "from taskqueue import TaskQueue, queueable\n",
    "from functools import partial"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# libraries 2\n",
    "# %pwd\n",
    "sys.path.append(os.path.abspath(\"../segmentation\"))\n",
    "# to import rootID_lookup and authentication_utils like below\n",
    "import rootID_lookup as IDlook\n",
    "import authentication_utils as auth"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "parser = argparse.ArgumentParser(description='get segIDs of parent neurons from csv files') \n",
    "parser.add_argument('-c', '--choose', help='specify the numer of pixels randomly chosen to get segID of parent neuron. default is all surroundinx pixels', default=0, type=int)\n",
    "parser.add_argument('-l', '--lease', help='lease_seconds for TaskQueue.poll. specify in seconds. default is 600sec', default=600, type=int)\n",
    "args = parser.parse_args()\n",
    "\n",
    "choose=args.choose\n",
    "lease=args.lease"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "np.random.seed(123)\n",
    "# queuepath = '/n/groups/htem/users/skuroda/nuclei_tasks'\n",
    "queuepath = '../Output/nuclei_tasks'\n",
    "# queuepath = '/n/groups/htem/users/skuroda/nuclei_output2'\n",
    "outputpath = '../Output/'\n",
    "size_xy = 160 # 160/(2**2)??\n",
    "# 128x128x160 is small\n",
    "# read csv\n",
    "df = pd.read_csv('../Output/info_cellbody.csv', header=0)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# cv setting\n",
    "seg = CloudVolume(auth.get_cv_path('FANC_production_segmentation')['url'], use_https=True, agglomerate=False, cache=True, progress=False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "create_task_queue()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Inserting: 7it [00:00, 12.09it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Done adding 7 tasks to queue at ../Output/nuclei_tasks\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "run_tasks_from_queue()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Working on tasks from filequeue \"../Output/nuclei_tasks\"\n",
      "INFO Running FunctionTask(('__main__', 'task_cellbody2neuron'),[6],{},\"e123c11b-372d-4aea-83c8-d09763369862\")  (id: e123c11b-372d-4aea-83c8-d09763369862)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Inserting: 7it [00:14, 12.09it/s]/usr/local/pip-global/ipykernel_launcher.py:26: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "Inserting: 7it [00:23,  3.39s/it]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "INFO Deleting e123c11b-372d-4aea-83c8-d09763369862\n",
      "INFO FunctionTask e123c11b-372d-4aea-83c8-d09763369862 succesfully executed in 29.74 sec.\n",
      "INFO Running FunctionTask(('__main__', 'task_cellbody2neuron'),[3],{},\"7a829302-077f-42af-8643-89c8bbfe859f\")  (id: 7a829302-077f-42af-8643-89c8bbfe859f)\n",
      "INFO Deleting 7a829302-077f-42af-8643-89c8bbfe859f\n",
      "INFO FunctionTask 7a829302-077f-42af-8643-89c8bbfe859f succesfully executed in 32.52 sec.\n",
      "INFO Running FunctionTask(('__main__', 'task_cellbody2neuron'),[0],{},\"7a9515c5-4f42-4f1f-a898-1802881e51d5\")  (id: 7a9515c5-4f42-4f1f-a898-1802881e51d5)\n",
      "INFO Deleting 7a9515c5-4f42-4f1f-a898-1802881e51d5\n",
      "INFO FunctionTask 7a9515c5-4f42-4f1f-a898-1802881e51d5 succesfully executed in 69.22 sec.\n",
      "INFO Running FunctionTask(('__main__', 'task_cellbody2neuron'),[4],{},\"c3e266fd-4413-4e3a-a466-dcc256411bb4\")  (id: c3e266fd-4413-4e3a-a466-dcc256411bb4)\n",
      "Interrupted. Exiting after this task completes. Press Ctrl-C again to exit now.\n",
      "Failed, retrying\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "functions listed below"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "def vol_shift(input): # Although np.roll is fast, this is very slow since this overuse RAM\n",
    "    # x plane\n",
    "    x_p = np.roll(input, 1, axis=0)\n",
    "    x_p[0,:,:] = 0\n",
    "    x_n = np.roll(input, -1, axis=0)\n",
    "    x_n[-1,:,:] = 0\n",
    "    # y plane\n",
    "    y_p = np.roll(input, 1, axis=1)\n",
    "    y_p[:,0,:] = 0\n",
    "    y_n = np.roll(input, -1, axis=1)\n",
    "    y_n[:,-1,:] = 0\n",
    "    # z plane\n",
    "    z_p = np.roll(input, 1, axis=2)\n",
    "    z_p[:,:,0] = 0\n",
    "    z_n = np.roll(input, -1, axis=2)\n",
    "    z_n[:,:,-1] = 0\n",
    "\n",
    "    sum = x_p + x_n + y_p + y_n + z_p + z_n\n",
    "    result = sum - input*6\n",
    "\n",
    "    return result"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "# global variable is pt, segid, sizexy, choose\n",
    "\n",
    "choose = 0\n",
    "\n",
    "@queueable\n",
    "def task_cellbody2neuron(i):\n",
    "  try:\n",
    "    cord_mip0 = df.iloc[i,0:3] #xyz coordinates\n",
    "    cord_mip2 = cord_mip0.values # change coordination from mip0 to mip2\n",
    "    cord_mip2[0]  = (cord_mip0.values[0] /(2**2))\n",
    "    cord_mip2[1]  = (cord_mip0.values[1] /(2**2))\n",
    "    cord_mip2 = cord_mip2.astype('int64')\n",
    "    id = df.iloc[i,3] #segid\n",
    "\n",
    "    if id == 0:\n",
    "      A = np.append(cord_mip0.values, id).astype('int64')\n",
    "      B = np.zeros(3, dtype = 'int64')\n",
    "      output = np.append(A, B) #xyz, id, 0,0,0\n",
    "    else:\n",
    "      seg_nuc = seg.download_point(pt=cord_mip2, segids=id, size=[size_xy, size_xy, 160], coord_resolution=[17.2, 17.2, 45.0])\n",
    "      # lowest resolution of seg is [17.2, 17.2, 45.0]\n",
    "      vol_temp = seg_nuc[:,:,:]\n",
    "      vol_temp[vol_temp>0] = 1 # change segID assigned to each cell body into 1\n",
    "      vol = np.squeeze(vol_temp)\n",
    "\n",
    "      filled = fill_voids.fill(vol, in_place=False) # fill the empty space with one \n",
    "      # ignore warning\n",
    "\n",
    "      shifted = vol_shift(filled) # shift the volume\n",
    "      shifted = shifted.astype('float32')\n",
    "      shifted[shifted>0] = 1\n",
    "      shifted[shifted<0] = 0\n",
    "\n",
    "      location_one = np.argwhere(shifted == 1)\n",
    "      len(location_one)\n",
    "\n",
    "      if len(location_one):\n",
    "        origin = seg_nuc.bounds.minpt # 3072,5248,1792\n",
    "        parent_coordinates_mip2 = np.add(np.array(location_one), origin)\n",
    "        parent_coordinates = parent_coordinates_mip2\n",
    "        parent_coordinates[:,0]  = (parent_coordinates_mip2[:,0] * 2**2)\n",
    "        parent_coordinates[:,1]  = (parent_coordinates_mip2[:,1] * 2**2)\n",
    "        parent_coordinates = parent_coordinates.astype('int64')\n",
    "\n",
    "        #random selection?\n",
    "        if choose == 0:\n",
    "          location_random = parent_coordinates\n",
    "        else:\n",
    "          index = np.random.choice(parent_coordinates.shape[0], size=choose, replace=False)\n",
    "          location_random = parent_coordinates[index]\n",
    "\n",
    "        # Lets get IDs using cell_body_coordinates\n",
    "        parent_IDs = IDlook.segIDs_from_pts_cv(pts=location_random, cv=seg, progress=False) #mip0\n",
    "\n",
    "        # save\n",
    "        uniqueID, count = np.unique(parent_IDs, return_counts=True)\n",
    "        unsorted_max_indices = np.argpartition(-count, 4)[:4]\n",
    "        topIDs = uniqueID[unsorted_max_indices] # gives me top5 IDs\n",
    "        topIDs2 = topIDs[~(topIDs == id)] # I hope this keeps order\n",
    "        topIDs3 = topIDs2[~(topIDs2 == 0)] # no zero\n",
    "        A = np.append(cord_mip0.values, id).astype('int64')\n",
    "        B = topIDs3.astype('int64')[0:3]\n",
    "        output = np.append(A, B) #top3\n",
    "        \n",
    "      else:\n",
    "        A = np.append(cord_mip0.values, id).astype('int64')\n",
    "        B = np.zeros(3, dtype = 'int64')\n",
    "        output = np.append(A, B) #xyz, id, 0,0,0\n",
    "\n",
    "      output_df = pd.DataFrame(columns=[\"x\", \"y\", \"z\", \"segIDs\", \"Parent1\", \"Parent2\", \"Parent3\"])\n",
    "      output_df.loc[0] = output\n",
    "      name = str(i)\n",
    "      output_df.to_csv(outputpath + '/' + 'cellbody_and_neuron_{}.csv'.format(name), index=False)\n",
    "\n",
    "    seg.cache.flush()\n",
    "\n",
    "  except Exception as e:\n",
    "    name=str(i)\n",
    "    with open(outputpath + '/' + '{}.log'.format(name), 'w') as logfile:\n",
    "      print(e, file=logfile)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "# task queue\n",
    "# global variable is lease\n",
    " \n",
    "def create_task_queue():\n",
    "    tq = TaskQueue('fq://' + queuepath)\n",
    "    tq.insert(( partial(task_cellbody2neuron, i) for i in range(len(df)) )) # NEW SCHOOL?\n",
    "    print('Done adding {} tasks to queue at {}'.format(len(df), queuepath))\n",
    "\n",
    "\n",
    "def run_tasks_from_queue():\n",
    "    tq = TaskQueue('fq://' + queuepath)\n",
    "    print('Working on tasks from filequeue \"{}\"'.format(queuepath))\n",
    "    tq.poll(\n",
    "        verbose=True, # prints progress\n",
    "        lease_seconds=600,\n",
    "        tally=True # makes tq.completed work, logs 1 byte per completed task\n",
    "    )\n",
    "    print('Done')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c3593f56db3fdc375a231e1c1fb5fc1dbab03dc3894478fa0aaa4bb9b486beca"
  },
  "kernelspec": {
   "display_name": "nuclei",
   "language": "python",
   "name": "nuclei"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}