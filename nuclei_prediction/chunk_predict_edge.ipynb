{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# chunk_predict\n",
    "1. make blocks\n",
    "2. download one block and see cell bodies inside the block\n",
    "3. get segIDs of these by asking neuroglancer with xyz coordinate of the cell body centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries 1\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import csv\n",
    "from tqdm import tqdm\n",
    "\n",
    "from cloudvolume import CloudVolume, view\n",
    "import cc3d\n",
    "from tifffile.tifffile import imwrite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries 2\n",
    "# %pwd\n",
    "sys.path.append(os.path.abspath(\"../segmentation\"))\n",
    "# to import rootID_lookup and authentication_utils like below\n",
    "\n",
    "import rootID_lookup as IDlook\n",
    "import authentication_utils as auth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv setting\n",
    "cv = CloudVolume(auth.get_cv_path('Image')['url'], use_https=True, agglomerate=False)\n",
    "# loading from US server to use mip0\n",
    "\n",
    "nuclei_cv = CloudVolume(\n",
    "    auth.get_cv_path('nuclei_map')['url'],\n",
    "    progress=False,\n",
    "    cache=True, # cache to disk to avoid repeated downloads\n",
    "    use_https=True,\n",
    "    autocrop=True,\n",
    "    bounded=False\n",
    ")\n",
    "\n",
    "seg = CloudVolume(auth.get_cv_path('FANC_production_segmentation')['url'], use_https=True, agglomerate=False, cache=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55188"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make grid to download chunked volumes\n",
    "[X,Y,Z]=cv.mip_volume_size(0)\n",
    "# [ 83968 223232   4390]\n",
    "\n",
    "# cv.mip_voxel_offset(0)\n",
    "# Vec(0,0,10, dtype=int64)\n",
    "\n",
    "# we don't need neck conncetive, so lets start below that area y > 75000\n",
    "\n",
    "step_xy = 128*2**4 # width of each chunk = x or y space between each chunk center in mip0\n",
    "step_z = 256 # depth of each chunk = z space between each chunk center in mip0\n",
    "\n",
    "start_x = 128*2**(4-1) # first chunk center\n",
    "start_y = 128*2**(4-1) + 73728 # step_xy*36=73728\n",
    "start_z = 256*2**(-1) +10  # 10 is offset\n",
    "\n",
    "centerX = np.arange(start_x, X, step_xy)\n",
    "centerY = np.arange(start_y, Y, step_xy)\n",
    "centerZ = np.arange(start_z, Z, step_z)\n",
    "\n",
    "# looks okay but there can be only a few space < step/2 at the end of these sequences, causing error when making chunks\n",
    "if (X - centerX[-1]) < start_x:\n",
    "    np.put(centerX, -1, X-start_x)\n",
    "else:\n",
    "    centerX = np.append(centerX, X-start_x)\n",
    "\n",
    "if (Y - centerY[-1]) < start_y:\n",
    "    np.put(centerY, -1, Y-start_y)\n",
    "else:\n",
    "    centerY = np.append(centerY, Y-start_y)\n",
    "\n",
    "if (Z - centerZ[-1]) < start_z:\n",
    "    np.put(centerZ, -1, Z-start_z)\n",
    "else:\n",
    "    centerZ = np.append(centerZ, Z-start_z)\n",
    "\n",
    "# make nx3 arrays of the chunk center coordinates\n",
    "chunk_center = np.array(np.meshgrid(centerX, centerY, centerZ), dtype='int64').T.reshape(-1,3)\n",
    "len(chunk_center)\n",
    "# 55188\n",
    "# entire volume was 83160"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "output=[]\n",
    "\n",
    "x_thres = 33-10 # 50/(4.3*2^4/45) = 50/1.53\n",
    "y_thres = 33-10\n",
    "z_thres = 50-10\n",
    "\n",
    "connectivity = 26\n",
    "\n",
    "# thresholding cell body size\n",
    "def mybbox(img):\n",
    "\n",
    "    x = np.any(img, axis=(1, 2))\n",
    "    y = np.any(img, axis=(0, 2))\n",
    "    z = np.any(img, axis=(0, 1))\n",
    "\n",
    "    xmin, xmax = np.where(x)[0][[0, -1]]\n",
    "    ymin, ymax = np.where(y)[0][[0, -1]]\n",
    "    zmin, zmax = np.where(z)[0][[0, -1]]\n",
    "\n",
    "    return xmin, xmax, ymin, ymax, zmin, zmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for loop\n",
    "# for i in tqdm(range(len(chunk_center))):\n",
    "\n",
    "\n",
    "# here we only use one chunk for testing\n",
    "# candidate: 39644, 35021(50176, 84992,  1920) has 4 in entire set!!\n",
    "# in order zxy\n",
    "\n",
    "# 35021 is 23219 in this setup\n",
    "\n",
    "nuclei = nuclei_cv.download_point(chunk_center[23219], mip=[68.8,68.8,45.0], size=(128, 128, 256) ) # mip0 and 4 only\n",
    "# nuclei = nuclei_cv.download_point(chunk_center[i], mip=[68.8,68.8,45.0], size=(128, 128, 256))\n",
    "# using mio4 to make it faster\n",
    "# 4.3*(2**4)*128/45=196"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view(nuclei)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nuclei_cv.cache.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell body detection\n",
    "# thresholding intensity\n",
    "mask_temp = nuclei[:,:,:]\n",
    "mask = np.where(mask_temp > 0.5, 1, 0)  \n",
    "\n",
    "# print(mask.shape) \n",
    "# (128, 128, 256, 1)\n",
    "mask_s = np.squeeze(mask)\n",
    "# print(mask_s.shape) \n",
    "# (128, 128, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save images\n",
    "# volume = mask_s.swapaxes(0, 2).astype('float32')\n",
    "# imwrite('../Output/mask_s.tif', volume, imagej=True)\n",
    "\n",
    "# check EM dataset\n",
    "# tokyo_cv = CloudVolume(\n",
    "#     auth.get_cv_path('Image_Tokyo')['url'],\n",
    "#     progress=False,\n",
    "#     cache=True, # cache to disk to avoid repeated downloads\n",
    "#     use_https=True\n",
    "# )\n",
    "\n",
    "# em = tokyo_cv.download_point(chunk_center[35021], mip=4, size=(128, 128, 256) )\n",
    "# view(em)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nuclei_cv.cache.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimate connected components\n",
    "# # 26-connectivity\n",
    "# https://en.wikipedia.org/wiki/Pixel_connectivity\n",
    "# https://github.com/seung-lab/connected-components-3d\n",
    "cc_out, N = cc3d.connected_components(mask_s, return_N=True, connectivity=connectivity) # free\n",
    "# print(N)\n",
    "# 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# thresholding cell body size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 54, 0, 14, 0, 35), (26, 111, 26, 109, 0, 28), (81, 127, 61, 125, 26, 130), (11, 88, 89, 127, 55, 157), (22, 116, 0, 65, 96, 226), (113, 127, 38, 81, 101, 173), (98, 127, 110, 127, 153, 236), (31, 105, 78, 127, 187, 255), (28, 57, 62, 73, 228, 235), (121, 127, 16, 47, 237, 255), (12, 58, 0, 11, 242, 255), (58, 66, 28, 36, 255, 255)]\n"
     ]
    }
   ],
   "source": [
    "list=[]\n",
    "for segid in range(1, N+1):\n",
    "  extracted_image = cc_out * (cc_out == segid)\n",
    "  bbox = mybbox(extracted_image)\n",
    "  list.append(bbox)\n",
    "\n",
    "print(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(104.0, 93.0, 78.0), (49.5, 108.0, 106.0), (69.0, 32.5, 161.0), (68.0, 102.5, 221.0)]\n"
     ]
    }
   ],
   "source": [
    "list2=[]\n",
    "for segid in range(0, N):\n",
    "  xwidth = list[segid][1] - list[segid][0]\n",
    "  ywidth = list[segid][3] - list[segid][2]\n",
    "  zwidth = list[segid][5] - list[segid][4]\n",
    "  if xwidth >= x_thres and ywidth >= y_thres and zwidth >= z_thres:\n",
    "    center = ((list[segid][1] + list[segid][0])/2,\n",
    "      (list[segid][3] + list[segid][2])/2,\n",
    "      (list[segid][5] + list[segid][4])/2)\n",
    "    list2.append(center)\n",
    "  else:\n",
    "    pass\n",
    "\n",
    "print(list2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Segmentation IDs: 100%|██████████| 4/4 [00:00<00:00,  5.94it/s]\n"
     ]
    }
   ],
   "source": [
    "# calculate center coordinates of cell bodies\n",
    "\n",
    "if len(list2): # segIDs_from_pts_cv makes error is there is none in list2\n",
    "    origin = nuclei.bounds.minpt # 3072,5248,1792\n",
    "    cell_body_coordinates_mip4 = np.add(np.array(list2), origin)\n",
    "    cell_body_coordinates = cell_body_coordinates_mip4\n",
    "    cell_body_coordinates[:,0]  = (cell_body_coordinates_mip4[:,0] * 2**4)\n",
    "    cell_body_coordinates[:,1]  = (cell_body_coordinates_mip4[:,1] * 2**4)\n",
    "    cell_body_coordinates = cell_body_coordinates.astype('int64')\n",
    "\n",
    "    # Lets get IDs using cell_body_coordinates\n",
    "    cell_body_IDs = IDlook.segIDs_from_pts_cv(pts=cell_body_coordinates, cv=seg) #mip0\n",
    "\n",
    "    # save\n",
    "    # type(cell_body_coordinates.shape)\n",
    "    cell_body_IDs_list = cell_body_IDs.tolist()\n",
    "    output.append(cell_body_IDs_list)\n",
    "    # df = pd.DataFrame({'cell_body_coordinates':cell_body_coordinates, 'cell_body_IDs':cell_body_IDs})\n",
    "    # print(df)\n",
    "else:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "nuclei_cv.cache.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['648518346490988223'], ['648518346492077650'], ['648518346505454978'], ['648518346490989503']]\n"
     ]
    }
   ],
   "source": [
    "# out from for loop\n",
    "sum = sum(output,[])\n",
    "output_s = set(sum)\n",
    "output_str = [str(n) for n in output_s]\n",
    "output_2D = np.array(output_str ).reshape(len(output_str ),1).tolist()\n",
    "print(output_2D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../Output/output.csv', 'w') as result:\n",
    "    writer = csv.writer(result)\n",
    "    writer.writerows(output_2D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ignore below, just testing a bit for finding neuron partners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = seg.download_point(segids=[648518346490989503], mip=0) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test kmeans\n",
    "# 648518346492077650\n",
    "\n",
    "mesh = seg.mesh.get(segids=648518346490989503)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh[648518346490989503].vertices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell body seg id overlap\n",
    "cell body and neuron id overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nuclei_cv.cache.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nuclei_cv.mip_volume_size(0)\n",
    "# Vec(86016,225776,4390, dtype=int64)\n",
    "# entire dataset\n",
    "# [ 83968 223232   4390]\n",
    "# why different"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c3593f56db3fdc375a231e1c1fb5fc1dbab03dc3894478fa0aaa4bb9b486beca"
  },
  "kernelspec": {
   "display_name": "nuclei",
   "language": "python",
   "name": "nuclei"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}