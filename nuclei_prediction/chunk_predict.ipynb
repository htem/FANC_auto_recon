{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# chunk_predict\n",
    "download chunks\n",
    "overlap is inevitable missing cell bodies is much more dangerous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pwd\n",
    "sys.path.append(os.path.abspath(\"../segmentation\"))\n",
    "# to import rootID_lookup "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import os\n",
    "\n",
    "from cloudvolume import CloudVolume, view\n",
    "import cc3d\n",
    "from tifffile.tifffile import imwrite\n",
    "\n",
    "import rootID_lookup as IDlook\n",
    "import authentication_utils as auth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting\n",
    "cv = CloudVolume(auth.get_cv_path('Image')['url'], use_https=True, agglomerate=False)\n",
    "# loading from US server to use mip0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "83160"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make grid to download chunked volumes\n",
    "[X,Y,Z]=cv.mip_volume_size(0)\n",
    "# [ 83968 223232   4390]\n",
    "# print(cv.mip_volume_size(0))\n",
    "# print(cv.mip_chunk_size(0))\n",
    "\n",
    "\n",
    "step_xy = 128*2**4 # width of each chunk = x or y space between each chunk center in mip0\n",
    "step_z = 256 # depth of each chunk = z space between each chunk center in mip0\n",
    "\n",
    "start_xy = 128*2**(4-1) # first chunk center\n",
    "start_z = 256*2**(-1) # first chunk center\n",
    "\n",
    "centerX = np.arange(start_xy, X, step_xy)\n",
    "centerY = np.arange(start_xy, Y, step_xy)\n",
    "centerZ = np.arange(start_z, Z, step_z)\n",
    "\n",
    "# looks okay but there can be only a few space < step/2 at the end of these sequences, causing error when making chunks\n",
    "if (X - centerX[-1]) < start_xy:\n",
    "    np.put(centerX, -1, X-start_xy)\n",
    "else:\n",
    "    centerX = np.append(centerX, X-start_xy)\n",
    "\n",
    "if (Y - centerY[-1]) < start_xy:\n",
    "    np.put(centerY, -1, Y-start_xy)\n",
    "else:\n",
    "    centerY = np.append(centerY, Y-start_xy)\n",
    "\n",
    "if (Z - centerZ[-1]) < start_z:\n",
    "    np.put(centerZ, -1, Z-start_z)\n",
    "else:\n",
    "    centerZ = np.append(centerZ, Z-start_z)\n",
    "\n",
    "# make nx3 arrays of the chunk center coordinates\n",
    "chunk_center = np.array(np.meshgrid(centerX, centerY, centerZ), dtype='uint32').T.reshape(-1,3)\n",
    "len(chunk_center)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "nuclei_cv = CloudVolume(\n",
    "    auth.get_cv_path('nuclei_map')['url'],\n",
    "    progress=False,\n",
    "    cache=True, # cache to disk to avoid repeated downloads\n",
    "    use_https=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for loop\n",
    "# here we only use one chunk for testing\n",
    "# candidate: 39644, 35021\n",
    "# set in order zxy\n",
    "# 35021 codes (50176, 84992,  1920)\n",
    "\n",
    "nuclei = nuclei_cv.download_point(chunk_center[35021], mip=[68.8,68.8,45.0], size=(128, 128, 256) ) # mip0 and 4 only\n",
    "# using mio4 to make it faster\n",
    "# 4.3*(2**4)*128/45=196"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view(nuclei)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nuclei_cv.cache.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell body detection\n",
    "# thresholding intensity\n",
    "mask_temp = nuclei[:,:,:]\n",
    "mask = np.where(mask_temp > 0.5, 1, 0)  \n",
    "\n",
    "# print(mask.shape) \n",
    "# (128, 128, 256, 1)\n",
    "mask_s = np.squeeze(mask)\n",
    "# print(mask_s.shape) \n",
    "# (128, 128, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" em_cv = CloudVolume(\\n    auth.get_cv_path('Image_Tokyo')['url'],\\n    progress=False,\\n    cache=True, # cache to disk to avoid repeated downloads\\n    use_https=True\\n)\\nem = em_cv.download_point(chunk_center[35021], mip=4, size=(128, 128, 256) )\\nview(em) \""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save images\n",
    "# volume = mask_s.swapaxes(0, 2).astype('float32')\n",
    "# imwrite('../Output/mask_s.tif', volume, imagej=True)\n",
    "\n",
    "# check EM dataset\n",
    "\"\"\" em_cv = CloudVolume(\n",
    "    auth.get_cv_path('Image_Tokyo')['url'],\n",
    "    progress=False,\n",
    "    cache=True, # cache to disk to avoid repeated downloads\n",
    "    use_https=True\n",
    ")\n",
    "em = em_cv.download_point(chunk_center[35021], mip=4, size=(128, 128, 256) )\n",
    "view(em) \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nuclei_cv.cache.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimate connected components\n",
    "# # 26-connectivity\n",
    "# https://en.wikipedia.org/wiki/Pixel_connectivity\n",
    "# https://github.com/seung-lab/connected-components-3d\n",
    "cc_out, N = cc3d.connected_components(mask_s, return_N=True, connectivity=26) # free\n",
    "# print(N)\n",
    "# 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "only 10 but detecting 2 more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# thresholding cell body size\n",
    "def mybbox(img):\n",
    "\n",
    "    x = np.any(img, axis=(1, 2))\n",
    "    y = np.any(img, axis=(0, 2))\n",
    "    z = np.any(img, axis=(0, 1))\n",
    "\n",
    "    xmin, xmax = np.where(x)[0][[0, -1]]\n",
    "    ymin, ymax = np.where(y)[0][[0, -1]]\n",
    "    zmin, zmax = np.where(z)[0][[0, -1]]\n",
    "\n",
    "    return xmin, xmax, ymin, ymax, zmin, zmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 55, 0, 14, 0, 45), (26, 113, 23, 111, 0, 38), (125, 126, 104, 104, 0, 1), (81, 127, 61, 125, 36, 140), (11, 88, 89, 127, 65, 167), (22, 116, 0, 65, 106, 236), (113, 127, 38, 81, 111, 183), (98, 127, 110, 127, 163, 246), (31, 105, 78, 127, 197, 255), (28, 57, 62, 73, 238, 245), (124, 127, 20, 43, 247, 255), (23, 49, 0, 4, 252, 255)]\n"
     ]
    }
   ],
   "source": [
    "list=[]\n",
    "for segid in range(1, N+1):\n",
    "  extracted_image = cc_out * (cc_out == segid)\n",
    "  bbox = mybbox(extracted_image)\n",
    "  list.append(bbox)\n",
    "\n",
    "print(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_thres = 33-10 # 50/(4.3*2^4/45) = 50/1.53\n",
    "y_thres = 33-10\n",
    "z_thres = 50-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(104.0, 93.0, 88.0), (49.5, 108.0, 116.0), (69.0, 32.5, 171.0), (68.0, 102.5, 226.0)]\n"
     ]
    }
   ],
   "source": [
    "list2=[]\n",
    "for segid in range(0, N):\n",
    "  X = list[segid][1] - list[segid][0]\n",
    "  Y = list[segid][3] - list[segid][2]\n",
    "  Z = list[segid][5] - list[segid][4]\n",
    "  if X >= x_thres and Y >= y_thres and Z >= z_thres:\n",
    "    center = ((list[segid][1] + list[segid][0])/2,\n",
    "      (list[segid][3] + list[segid][2])/2,\n",
    "      (list[segid][5] + list[segid][4])/2)\n",
    "    list2.append(center)\n",
    "  else:\n",
    "    pass\n",
    "\n",
    "print(list2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[50816 85456  1880]\n",
      " [49944 85696  1908]\n",
      " [50256 84488  1963]\n",
      " [50240 85608  2018]]\n"
     ]
    }
   ],
   "source": [
    "# calculate center coordinates of cell bodies\n",
    "# assume bbox provides origin of the dataset...\n",
    "origin = nuclei.bounds.minpt # 3072,5248,1792\n",
    "cell_body_coordinates_mip4 = np.add(np.array(list2), origin)\n",
    "cell_body_coordinates = cell_body_coordinates_mip4\n",
    "cell_body_coordinates[:,0]  = (cell_body_coordinates_mip4[:,0] * 2**4)\n",
    "cell_body_coordinates[:,1]  = (cell_body_coordinates_mip4[:,1] * 2**4)\n",
    "cell_body_coordinates = cell_body_coordinates.astype('uint32')\n",
    "print(cell_body_coordinates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Segmentation IDs: 100%|██████████| 4/4 [00:06<00:00,  1.51s/it]\n"
     ]
    }
   ],
   "source": [
    "# Lets get IDs using cell_body_coordinates\n",
    "seg = CloudVolume(auth.get_cv_path('FANC_production_segmentation')['url'], use_https=True, agglomerate=False)\n",
    "a = IDlook.segIDs_from_pts_cv(pts=cell_body_coordinates, cv=seg) #mip0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([648518346490989503, 648518346490988223, 648518346492077650,\n",
       "       648518346505454978], dtype=uint64)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell body seg id overlap\n",
    "cell body and neuron id overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nuclei_cv.cache.flush()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c3593f56db3fdc375a231e1c1fb5fc1dbab03dc3894478fa0aaa4bb9b486beca"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 64-bit ('nuclei': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}