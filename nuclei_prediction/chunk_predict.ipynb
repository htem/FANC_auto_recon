{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# chunk_predict\n",
    "download chunks\n",
    "overlap is inevitable missing cell bodies is much more dangerous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pwd\n",
    "sys.path.append(os.path.abspath(\"../segmentation\"))\n",
    "# to import rootID_lookup "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import os\n",
    "\n",
    "from cloudvolume import CloudVolume, view\n",
    "import cc3d\n",
    "from tifffile.tifffile import imwrite\n",
    "\n",
    "import rootID_lookup as IDlook\n",
    "import authentication_utils as auth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting\n",
    "cv = CloudVolume(auth.get_cv_path('Image')['url'], use_https=True, agglomerate=False)\n",
    "# loading from US server to use mip0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "83160"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make grid to download chunked volumes\n",
    "[X,Y,Z]=cv.mip_volume_size(0)\n",
    "# [ 83968 223232   4390]\n",
    "# print(cv.mip_volume_size(0))\n",
    "# print(cv.mip_chunk_size(0))\n",
    "\n",
    "\n",
    "step_xy = 128*2**4 # width of each chunk = x or y space between each chunk center in mip0\n",
    "step_z = 256 # depth of each chunk = z space between each chunk center in mip0\n",
    "\n",
    "start_xy = 128*2**(4-1) # first chunk center\n",
    "start_z = 256*2**(-1) # first chunk center\n",
    "\n",
    "centerX = np.arange(start_xy, X, step_xy)\n",
    "centerY = np.arange(start_xy, Y, step_xy)\n",
    "centerZ = np.arange(start_z, Z, step_z)\n",
    "\n",
    "# looks okay but there can be only a few space < step/2 at the end of these sequences, causing error when making chunks\n",
    "if (X - centerX[-1]) < start_xy:\n",
    "    np.put(centerX, -1, X-start_xy)\n",
    "else:\n",
    "    centerX = np.append(centerX, X-start_xy)\n",
    "\n",
    "if (Y - centerY[-1]) < start_xy:\n",
    "    np.put(centerY, -1, Y-start_xy)\n",
    "else:\n",
    "    centerY = np.append(centerY, Y-start_xy)\n",
    "\n",
    "if (Z - centerZ[-1]) < start_z:\n",
    "    np.put(centerZ, -1, Z-start_z)\n",
    "else:\n",
    "    centerZ = np.append(centerZ, Z-start_z)\n",
    "\n",
    "# make nx3 arrays of the chunk center coordinates\n",
    "chunk_center = np.array(np.meshgrid(centerX, centerY, centerZ), dtype='uint32').T.reshape(-1,3)\n",
    "len(chunk_center)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "nuclei_cv = CloudVolume(\n",
    "    auth.get_cv_path('nuclei_map')['url'],\n",
    "    progress=False,\n",
    "    cache=True, # cache to disk to avoid repeated downloads\n",
    "    use_https=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for loop\n",
    "# here we only use one chunk for testing\n",
    "# candidate: 39644, 35021\n",
    "# set in order zxy\n",
    "# 35021 codes (50176, 84992,  1920)\n",
    "\n",
    "nuclei = nuclei_cv.download_point(chunk_center[35021], mip=[68.8,68.8,45.0], size=(128, 128, 256) ) # mip0 and 4 only\n",
    "# using mio4 to make it faster\n",
    "# 4.3*(2**4)*128/45=196"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view(nuclei)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nuclei_cv.cache.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell body detection\n",
    "# thresholding intensity\n",
    "mask_temp = nuclei[:,:,:]\n",
    "mask = np.where(mask_temp > 0.5, 1, 0)  \n",
    "\n",
    "# print(mask.shape) \n",
    "# (128, 128, 256, 1)\n",
    "mask_s = np.squeeze(mask)\n",
    "# print(mask_s.shape) \n",
    "# (128, 128, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save images\n",
    "# volume = mask_s.swapaxes(0, 2).astype('float32')\n",
    "# imwrite('../Output/mask_s.tif', volume, imagej=True)\n",
    "\n",
    "# check EM dataset\n",
    "\"\"\" em_cv = CloudVolume(\n",
    "    auth.get_cv_path('Image_Tokyo')['url'],\n",
    "    progress=False,\n",
    "    cache=True, # cache to disk to avoid repeated downloads\n",
    "    use_https=True\n",
    ")\n",
    "em = em_cv.download_point(chunk_center[35021], mip=4, size=(128, 128, 256) )\n",
    "view(em) \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nuclei_cv.cache.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimate connected components\n",
    "# # 26-connectivity\n",
    "# https://en.wikipedia.org/wiki/Pixel_connectivity\n",
    "# https://github.com/seung-lab/connected-components-3d\n",
    "cc_out, N = cc3d.connected_components(mask_s, return_N=True, connectivity=26) # free\n",
    "# print(N)\n",
    "# 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "only 10 but detecting 2 more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# thresholding cell body size\n",
    "def mybbox(img):\n",
    "\n",
    "    x = np.any(img, axis=(1, 2))\n",
    "    y = np.any(img, axis=(0, 2))\n",
    "    z = np.any(img, axis=(0, 1))\n",
    "\n",
    "    xmin, xmax = np.where(x)[0][[0, -1]]\n",
    "    ymin, ymax = np.where(y)[0][[0, -1]]\n",
    "    zmin, zmax = np.where(z)[0][[0, -1]]\n",
    "\n",
    "    return xmin, xmax, ymin, ymax, zmin, zmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 55, 0, 14, 0, 45), (26, 113, 23, 111, 0, 38), (125, 126, 104, 104, 0, 1), (81, 127, 61, 125, 36, 140), (11, 88, 89, 127, 65, 167), (22, 116, 0, 65, 106, 236), (113, 127, 38, 81, 111, 183), (98, 127, 110, 127, 163, 246), (31, 105, 78, 127, 197, 255), (28, 57, 62, 73, 238, 245), (124, 127, 20, 43, 247, 255), (23, 49, 0, 4, 252, 255)]\n"
     ]
    }
   ],
   "source": [
    "list=[]\n",
    "for segid in range(1, N+1):\n",
    "  extracted_image = cc_out * (cc_out == segid)\n",
    "  bbox = mybbox(extracted_image)\n",
    "  list.append(bbox)\n",
    "\n",
    "print(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_thres = 33-10 # 50/(4.3*2^4/45) = 50/1.53\n",
    "y_thres = 33-10\n",
    "z_thres = 50-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(104.0, 93.0, 88.0), (49.5, 108.0, 116.0), (69.0, 32.5, 171.0), (68.0, 102.5, 226.0)]\n"
     ]
    }
   ],
   "source": [
    "list2=[]\n",
    "for segid in range(0, N):\n",
    "  X = list[segid][1] - list[segid][0]\n",
    "  Y = list[segid][3] - list[segid][2]\n",
    "  Z = list[segid][5] - list[segid][4]\n",
    "  if X >= x_thres and Y >= y_thres and Z >= z_thres:\n",
    "    center = ((list[segid][1] + list[segid][0])/2,\n",
    "      (list[segid][3] + list[segid][2])/2,\n",
    "      (list[segid][5] + list[segid][4])/2)\n",
    "    list2.append(center)\n",
    "  else:\n",
    "    pass\n",
    "\n",
    "print(list2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate center coordinates of cell bodies\n",
    "# assume bbox provides origin of the dataset...\n",
    "origin = nuclei.bounds.minpt # 3072,5248,1792\n",
    "cell_body_coordinates_mip4 = np.add(np.array(list2), origin)\n",
    "cell_body_coordinates = (cell_body_coordinates_mip4 * 2**4).astype('uint32')\n",
    "# print(cell_body_coordinates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'CloudVolumePrecomputed' object has no attribute 'agglomerate'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_84411/593878917.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Lets get IDs using cell_body_coordinates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mIDlook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msegIDs_from_pts_cv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcell_body_coordinates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#mip0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/workspaces/FANC_auto_recon/segmentation/rootID_lookup.py\u001b[0m in \u001b[0;36msegIDs_from_pts_cv\u001b[0;34m(pts, cv, n, max_tries, return_roots)\u001b[0m\n\u001b[1;32m    198\u001b[0m     '''\n\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magglomerate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m         \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magglomerate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'CloudVolumePrecomputed' object has no attribute 'agglomerate'"
     ]
    }
   ],
   "source": [
    "# Lets get IDs using cell_body_coordinates\n",
    "\n",
    "a = IDlook.segIDs_from_pts_cv(pts=cell_body_coordinates, cv=cv) #mip0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "AuthenticationError",
     "evalue": "No Graphene authentication token was provided. Does ~/.cloudvolume/secrets/cave-secret.json exist?",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAuthenticationError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_84411/3648028263.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mseg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCloudVolume\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mauth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_cv_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'FANC_production_segmentation'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'url'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_https\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0magglomerate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magglomerate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/pip-global/cloudvolume/cloudvolume.py\u001b[0m in \u001b[0;36m__new__\u001b[0;34m(cls, cloudpath, mip, bounded, autocrop, fill_missing, cache, compress_cache, cdn_cache, progress, info, provenance, compress, compress_level, non_aligned_writes, parallel, delete_black_uploads, background_color, green_threads, use_https, max_redirects, mesh_dir, skel_dir, agglomerate, secrets)\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstrict_extract\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcloudpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mREGISTERED_PLUGINS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 207\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mREGISTERED_PLUGINS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    208\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m       raise UnsupportedFormatError(\n",
      "\u001b[0;32m/usr/local/pip-global/cloudvolume/datasource/graphene/__init__.py\u001b[0m in \u001b[0;36mcreate_graphene\u001b[0;34m(cloudpath, mip, bounded, autocrop, fill_missing, cache, compress_cache, cdn_cache, progress, info, provenance, compress, parallel, delete_black_uploads, background_color, green_threads, use_https, mesh_dir, skel_dir, agglomerate, secrets, **kwargs)\u001b[0m\n\u001b[1;32m     45\u001b[0m       \u001b[0minfo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprovenance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprovenance\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m       \u001b[0muse_https\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_https\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0magglomerate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0magglomerate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m       \u001b[0mauth_token\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msecrets\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m     )\n\u001b[1;32m     49\u001b[0m     \u001b[0;31m# Resetting the cache is necessary because\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/pip-global/cloudvolume/datasource/graphene/metadata.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, cloudpath, use_https, use_auth, auth_token, agglomerate, *args, **kwargs)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0muse_auth\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m       self.auth_header = {\n\u001b[0;32m---> 92\u001b[0;31m         \u001b[0;34m\"Authorization\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"Bearer %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_token\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mauth_token\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m       }\n\u001b[1;32m     94\u001b[0m     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'use_https'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muse_https\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/pip-global/cloudvolume/datasource/graphene/metadata.py\u001b[0m in \u001b[0;36mparse_token\u001b[0;34m(self, auth_token)\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m       raise exceptions.AuthenticationError(\n\u001b[0;32m--> 121\u001b[0;31m         \u001b[0;34m\"No Graphene authentication token was provided. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m         \u001b[0;34m\"Does ~/.cloudvolume/secrets/cave-secret.json exist?\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m       )\n",
      "\u001b[0;31mAuthenticationError\u001b[0m: No Graphene authentication token was provided. Does ~/.cloudvolume/secrets/cave-secret.json exist?"
     ]
    }
   ],
   "source": [
    "seg = CloudVolume(auth.get_cv_path('FANC_production_segmentation')['url'], use_https=True, agglomerate=False)\n",
    "print(seg.agglomerate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = IDlook.segIDs_from_pts_cv(pts,cv,n=100000,max_tries = 3,return_roots=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nuclei_cv.cache.flush()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c3593f56db3fdc375a231e1c1fb5fc1dbab03dc3894478fa0aaa4bb9b486beca"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 64-bit ('nuclei': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}