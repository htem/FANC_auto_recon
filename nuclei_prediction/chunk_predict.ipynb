{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# chunk_predict\n",
    "download chunks\n",
    "overlap is inevitable missing cell bodies is much more dangerous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pwd\n",
    "sys.path.append(os.path.abspath(\"../segmentation\"))\n",
    "# to import rootID_lookup "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import os\n",
    "\n",
    "from cloudvolume import CloudVolume, view\n",
    "import cc3d\n",
    "from tifffile.tifffile import imwrite\n",
    "\n",
    "import rootID_lookup as IDlook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 83968 223232   4390]\n"
     ]
    }
   ],
   "source": [
    "# setting\n",
    "cv = CloudVolume('precomputed://gs://zetta_lee_fly_vnc_001_precomputed/fanc_v4_em', use_https=True)\n",
    "# loading from US server to use mip0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "83160"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make grid to download chunked volumes\n",
    "[X,Y,Z]=cv.mip_volume_size(0)\n",
    "# [ 83968 223232   4390]\n",
    "# print(cv.mip_volume_size(0))\n",
    "# print(cv.mip_chunk_size(0))\n",
    "\n",
    "\n",
    "step_xy = 128*2**4 # width of each chunk = x or y space between each chunk center in mip0\n",
    "step_z = 256 # depth of each chunk = z space between each chunk center in mip0\n",
    "\n",
    "start_xy = 128*2**(4-1) # first chunk center\n",
    "start_z = 256*2**(-1) # first chunk center\n",
    "\n",
    "centerX = np.arange(start_xy, X, step_xy)\n",
    "centerY = np.arange(start_xy, Y, step_xy)\n",
    "centerZ = np.arange(start_z, Z, step_z)\n",
    "\n",
    "# looks okay but there can be only a few space < step/2 at the end of these sequences, causing error when making chunks\n",
    "if (X - centerX[-1]) < start_xy:\n",
    "    np.put(centerX, -1, X-start_xy)\n",
    "else:\n",
    "    centerX = np.append(centerX, X-start_xy)\n",
    "\n",
    "if (Y - centerY[-1]) < start_xy:\n",
    "    np.put(centerY, -1, Y-start_xy)\n",
    "else:\n",
    "    centerY = np.append(centerY, Y-start_xy)\n",
    "\n",
    "if (Z - centerZ[-1]) < start_z:\n",
    "    np.put(centerZ, -1, Z-start_z)\n",
    "else:\n",
    "    centerZ = np.append(centerZ, Z-start_z)\n",
    "\n",
    "# make nx3 arrays of the chunk center coordinates\n",
    "chunk_center = np.array(np.meshgrid(centerX, centerY, centerZ)).T.reshape(-1,3)\n",
    "len(chunk_center)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(centerZ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.02400e+03, 1.02400e+03, 1.28000e+02],\n",
       "       [1.02400e+03, 1.02400e+03, 3.84000e+02],\n",
       "       [1.02400e+03, 1.02400e+03, 6.40000e+02],\n",
       "       ...,\n",
       "       [8.29440e+04, 2.22208e+05, 3.96800e+03],\n",
       "       [8.29440e+04, 2.22208e+05, 4.22400e+03],\n",
       "       [8.29440e+04, 2.22208e+05, 4.26200e+03]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[256 256  16]\n"
     ]
    }
   ],
   "source": [
    "nuclei_cv = CloudVolume(\n",
    "    'precomputed://gs://ranl_scratch_zetta_30/neuroglancer/nuclei/3d528bc3def9f51e09ae55e68ee46518',\n",
    "    progress=False,\n",
    "    cache=True, # cache to disk to avoid repeated downloads\n",
    "    use_https=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for chunk in gridpoints\n",
    "nuclei = nuclei_cv.download_point( (52785, 86885, 1894), mip=4, size=(128, 128, 256) ) # mip0 and 4 only\n",
    "# using mio4 to make it faster\n",
    "# 4.3*(2**4)*128/45=196"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following steps are similar to predict.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# size of entire FANC image in mip4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img.cache.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c3593f56db3fdc375a231e1c1fb5fc1dbab03dc3894478fa0aaa4bb9b486beca"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 64-bit ('nuclei': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}