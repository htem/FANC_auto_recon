{
    "cells": [
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# proofread_soma\n",
                "For our 2nd run of quality check, we used a different approach. We looked at `'soma_xyz'` instead of `'nuc_xyz'`, and also took a note whether the `'soma_xyz'` located inside or outside neurons. This information became helpful when we merge nuclei and cytosols later."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import numpy as np\n",
                "import pyperclip\n",
                "import pandas as pd\n",
                "import pyperclip\n",
                "from cloudvolume import CloudVolume, view, Bbox\n",
                "from nglui import statebuilder,annotation,easyviewer,parser\n",
                "from nglui.statebuilder import *\n",
                "from nglui.nglite import *\n",
                "import json\n",
                "import sys\n",
                "import os\n",
                "from datetime import datetime\n",
                "from caveclient import CAVEclient\n",
                "from ..lib import get_cv_path\n",
                "from fanc import rootID_lookup as IDlook"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "datastack_name = 'fanc_production_mar2021'\n",
                "client = CAVEclient(datastack_name)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df_progress = pd.read_csv('../Output/proofread_soma_temp.csv', header=0)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df = df_progress[df_progress.is_neuron=='y']"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Create Neuroglancer links\n",
                "We did not use lines for this QC. Instead, we decided to use `linked_segmentation_layer` functionality. See [this example](https://github.com/seung-lab/NeuroglancerAnnotationUI/blob/master/examples/statebuilder_examples.ipynb) as well. Besically, when you jumped to a soma point on the annotation layer, you will not only find your soma point in the center of your screen, but also your soma with some random color based on`'nuc_xyz'`. This is very helpful to guess the spatial relationship between `'nuc_xyz'` and `'soma_xyz'` (e.g., if a soma is inside neuron and has some color, `'nuc_xyz'` is also likely to be inside that neuron). The previous method of using line was good, but the line itself was too thin to find and you cannot change it."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "xyz_df = df.reindex(columns=['nuc_xyz', 'soma_xyz', 'nucID'])\n",
                "xyz_df.columns =['nuc_xyz', 'soma_xyz', 'id']\n",
                "nuc_xyz_df = df['nuc_xyz'].str.strip('()').str.split(',',expand=True)\n",
                "soma_xyz_df = df['soma_xyz'].str.strip('()').str.split(',',expand=True)\n",
                "xyz_df['nuc_xyz'] = nuc_xyz_df.astype(int).values.tolist()\n",
                "xyz_df['soma_xyz'] = soma_xyz_df.astype(int).values.tolist()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "nuc_xyz_df = nuc_xyz_df.set_axis(['Col_x', 'Col_y', 'Col_z'], axis=1)\n",
                "sorted_z = nuc_xyz_df.astype(int).sort_values(by=['Col_z'], ascending=True)\n",
                "sorted_xz = sorted_z.astype(int).sort_values(by=['Col_x'], ascending=True)\n",
                "sorted_indices = sorted_xz.astype(int).sort_values(by=['Col_y'], ascending=True).index\n",
                "xyz_df = xyz_df.reindex(sorted_indices).reset_index(drop=True)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "datastack_name = 'fanc_production_mar2021'\n",
                "client = CAVEclient(datastack_name)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "client.materialize.version = client.materialize.get_versions()[-1]\n",
                "nuc_from_cave = client.materialize.query_table('nuclei_aug2021ver2')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "latest_nuc_segid = nuc_from_cave.reindex(columns=['id', 'pt_root_id'])\n",
                "merged = xyz_df.merge(latest_nuc_segid, how='left', on='id')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ..., and make them into points\n",
                "points = PointMapper('soma_xyz', linked_segmentation_column='pt_root_id')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# make Neuroglancer link\n",
                "imgTokyo = ImageLayerConfig(name = 'FANCv4-jp',\n",
                "                                    source = get_cv_path('Image_Tokyo')['url'])\n",
                "img = ImageLayerConfig(name = 'FANCv4',\n",
                "                                    source = get_cv_path('Image')['url'])\n",
                "seg = SegmentationLayerConfig(name = 'seg_Mar2021_proofreading',\n",
                "                                    source = get_cv_path('FANC_production_segmentation')['url'])          \n",
                "\n",
                "ann = AnnotationLayerConfig(name='soma_Aug2021',\n",
                "                            mapping_rules=points,\n",
                "                            linked_segmentation_layer='seg',\n",
                "                            tags=['inside', 'outside', 'need_check'],\n",
                "                            active = True)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "view_options = {\"layout\": \"xy\"}\n",
                "\n",
                "memory_options = {\"gpuMemoryLimit\": 4000000000,\n",
                "                  \"systemMemoryLimit\": 9000000000,\n",
                "                  \"concurrentDownloads\": 64,\n",
                "                  \"jsonStateServer\": \"https://global.daf-apis.com/nglstate/api/v1/post\"}\n",
                "\n",
                "\n",
                "sb = StateBuilder(layers=[imgTokyo, seg, img, ann],\n",
                "                  resolution=[4.3,4.3,45],\n",
                "                  view_kws=view_options)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "LINK=[]\n",
                "k=500\n",
                "minidfs = [merged.loc[i:i+k-1, :] for i in range(0, len(merged), k)]\n",
                "for dftmp in minidfs:\n",
                "    # csb = ChainedStateBuilder([sb, vs])                             \n",
                "    state = json.loads(sb.render_state(dftmp, return_as='json'))\n",
                "    state.update(memory_options)\n",
                "    jsn_id = client.state.upload_state_json(state)\n",
                "    output = client.state.build_neuroglancer_url(jsn_id, get_cv_path('neuroglancer_base')['url'])\n",
                "    LINK.append(output)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# save into csv\n",
                "LINK2 = pd.DataFrame(LINK)\n",
                "LINK2.to_csv('../Output/links_20211223soma.csv', index=False, header=False)\n",
                "# do the exact same thing as 1st time"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Extract tags\n",
                "We extracted annotation tags from the result similar to our 1st QC."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# only for the 1st time\n",
                "\n",
                "# df['is_inside']=\"\"\n",
                "# df['is_outside']=\"\"\n",
                "# df['is_false_positive']=\"\"\n",
                "# df['is_duplicated']=\"\"\n",
                "# df.to_csv('../Output/proofread_soma_temp.csv', index=False)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df_progress = pd.read_csv(\"../Output/proofread_soma_temp.csv\", header=0)\n",
                "prfrd = pd.read_table(\"../Output/soma_proofread_ver3_mistake_fixedfromver1.tsv\", usecols = ['new link'])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "rsplitted = prfrd['new link'].dropna(how='all').str.rsplit('/', 1)\n",
                "new_id = list()\n",
                "for i in rsplitted.index:\n",
                "    new_id.append(rsplitted.loc[i][1])\n",
                "\n",
                "print(len(new_id))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "mylist = []\n",
                "\n",
                "for i in range(len(new_id)):\n",
                "    state_id = int(new_id[i])\n",
                "    state = client.state.get_state_json(state_id)\n",
                "\n",
                "    # extract info from json state\n",
                "    nuc_tags = parser.tag_dictionary(state,parser.annotation_layers(state)[0])\n",
                "    anno_lists = parser.point_annotations(state,parser.annotation_layers(state)[0], tags=True)\n",
                "\n",
                "    temp = pd.DataFrame({'anno_points': anno_lists[0],\n",
                "                     'anno_tags': anno_lists[1]})\n",
                "\n",
                "    # convert [] to [0]\n",
                "    for j in range(len(temp)):\n",
                "        if (len(temp.iloc[j,1]) == 0) or (len(temp.iloc[j,1]) >= 2): # make dup to 0 for now....\n",
                "            temp.iloc[j,1] = [0]\n",
                "            # temp['anno_tags']\n",
                "\n",
                "    temp['anno_tags'] = np.concatenate(temp['anno_tags']).astype(int)\n",
                "    temp['anno_tags'] = temp['anno_tags'].replace(nuc_tags)\n",
                "\n",
                "    mylist.append(temp)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df_new = pd.concat(mylist).reset_index()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print('inside neuron are {}'.format(sum(df_new['anno_tags']=='inside')))\n",
                "print('outside neuron are {}'.format(sum(df_new['anno_tags']=='outside')))\n",
                "print('need_check are {}'.format(sum(df_new['anno_tags']=='need_check')))\n",
                "print('anything else? are {}'.format(sum(df_new['anno_tags']==0)))\n",
                "print('in total {}'.format(len(df_new)))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df_new.drop(\"index\", axis=1).to_csv('../Output/soma_proofread_ver3_extracted.csv', index=False)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df_new2 = df_new[(df_new['anno_tags']!='inside') & (df_new['anno_tags']!='outside')]\n",
                "print(len(df_new2))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# create xyz_df from csv\n",
                "xyz_df = xyz_df.loc[df_new2.index]\n",
                "# go back to the cell above and create new links"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## X. Save final results\n",
                "After repeating the QC process and proofreading all the putative nuclei, we saved them into a single csv file."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df_new = pd.read_csv(\"../Output/soma_proofread_extracted.csv\", header=0)\n",
                "df_new2 = pd.read_csv(\"../Output/soma_proofread_ver2_extracted.csv\", header=0)\n",
                "df_new3 = pd.read_csv('../Output/soma_proofread_ver3_extracted.csv', header=0)\n",
                "df_progress = pd.read_csv(\"../Output/proofread_soma_temp.csv\", header=0)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print('total num of registered nuclei {}'.format(len(df_progress)))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "i = df_new\n",
                "print('df_new')\n",
                "print('inside neuron are {}'.format(sum(i['anno_tags']=='inside')))\n",
                "print('outside neuron are {}'.format(sum(i['anno_tags']=='outside')))\n",
                "print('need_check are {}'.format(sum(i['anno_tags']=='need_check')))\n",
                "print('anything else? are {}'.format(sum(i['anno_tags']=='0')))\n",
                "print('in total {}'.format(len(i)))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "i = df_new2\n",
                "print('df_new2')\n",
                "print('inside neuron are {}'.format(sum(i['anno_tags']=='inside')))\n",
                "print('outside neuron are {}'.format(sum(i['anno_tags']=='outside')))\n",
                "print('need_check/glia are {}'.format(sum(i['anno_tags']=='need_check')))\n",
                "print('anything else? are {}'.format(sum(i['anno_tags']=='0')))\n",
                "print('in total {}'.format(len(i)))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "i = df_new3\n",
                "print('df_new3')\n",
                "print('inside neuron are {}'.format(sum(i['anno_tags']=='inside')))\n",
                "print('outside neuron are {}'.format(sum(i['anno_tags']=='outside')))\n",
                "print('need_check/glia are {}'.format(sum(i['anno_tags']=='need_check')))\n",
                "print('anything else? are {}'.format(sum(i['anno_tags']=='0')))\n",
                "print('in total {}'.format(len(i)))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "i = df_new.reindex()\n",
                "test1 = []\n",
                "\n",
                "for j in range(len(i)):\n",
                "    nuc_loc_temp = i['anno_points'].values[j].strip('[]')\n",
                "    nuc_loc = '(' + nuc_loc_temp + ')'\n",
                "    nuc_tag = i['anno_tags'].values[j]\n",
                "    if nuc_loc in df_progress['soma_xyz'].values:\n",
                "        idx = df_progress.index[df_progress['soma_xyz'] == nuc_loc]\n",
                "        if nuc_tag == 'inside':\n",
                "            df_progress.at[idx,'is_inside'] = 'y'\n",
                "        elif nuc_tag == 'outside':\n",
                "            df_progress.at[idx,'is_outside'] = 'y'\n",
                "    else:\n",
                "        test1.append(j)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "i = df_new2.reindex()\n",
                "test2 = []\n",
                "\n",
                "for j in range(len(i)):\n",
                "    nuc_loc_temp = i['anno_points'].values[j].strip('[]')\n",
                "    nuc_loc = '(' + nuc_loc_temp + ')'\n",
                "    nuc_tag = i['anno_tags'].values[j]\n",
                "    if nuc_loc in df_progress['soma_xyz'].values:\n",
                "        idx = df_progress.index[df_progress['soma_xyz'] == nuc_loc]\n",
                "        if nuc_tag == 'inside':\n",
                "            df_progress.at[idx,'is_inside'] = 'y'\n",
                "        elif nuc_tag == 'outside':\n",
                "            df_progress.at[idx,'is_outside'] = 'y'\n",
                "        elif nuc_tag == 'need_check':\n",
                "            df_progress.at[idx,'is_neuron'] = 'NaN'\n",
                "            df_progress.at[idx,'is_glia'] = 'y'\n",
                "    else:\n",
                "        test2.append(j)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "i = df_new3.reindex()\n",
                "test3 = []\n",
                "\n",
                "for j in range(len(i)):\n",
                "    nuc_loc_temp = i['anno_points'].values[j].strip('[]')\n",
                "    nuc_loc = '(' + nuc_loc_temp + ')'\n",
                "    nuc_tag = i['anno_tags'].values[j]\n",
                "    if nuc_loc in df_progress['soma_xyz'].values:\n",
                "        idx = df_progress.index[df_progress['soma_xyz'] == nuc_loc]\n",
                "        if nuc_tag == 'inside':\n",
                "            df_progress.at[idx,'is_inside'] = 'y'\n",
                "        elif nuc_tag == 'outside':\n",
                "            df_progress.at[idx,'is_outside'] = 'y'\n",
                "        elif nuc_tag == 'need_check':\n",
                "            df_progress.at[idx,'is_neuron'] = 'NaN'\n",
                "            df_progress.at[idx,'is_glia'] = 'y'\n",
                "    else:\n",
                "        test3.append(j)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print('neuron are {}'.format(sum(df_progress.is_neuron=='y')))\n",
                "print('glia are {}'.format(sum(df_progress.is_glia=='y')))\n",
                "print('inside are {}'.format(sum(df_progress.is_inside=='y')))\n",
                "print('outside are {}'.format(sum(df_progress.is_outside=='y')))\n",
                "print('in total {}'.format(len(df_progress)))"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Then, we noticed that some of them were labeled wrong and we still needed to fix them."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "glia_but_inside = df_progress[(df_progress.is_glia=='y') & (df_progress.is_inside=='y')]\n",
                "glia_but_inside"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# first of all, the last one 72622194198315045 is neuron...\n",
                "this_is_neuron_idx = df_progress.index[df_progress['nucID'] == 72622194198315045]\n",
                "df_progress.loc[this_is_neuron_idx]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df_progress.at[this_is_neuron_idx,'is_neuron'] = 'y'\n",
                "df_progress.at[this_is_neuron_idx,'is_glia'] = 'NaN'"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# now lets see glia but inside again\n",
                "glia_but_inside2 = df_progress[(df_progress.is_glia=='y') & (df_progress.is_inside=='y')]\n",
                "glia_but_inside2"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# these need to be empty in is_inside\n",
                "i = glia_but_inside2.reindex()\n",
                "\n",
                "for j in range(len(i)):\n",
                "    nucID_temp = i['nucID'].values[j]\n",
                "    this_shoud_not_have_inside_idx = df_progress.index[df_progress['nucID'] == nucID_temp]\n",
                "    df_progress.at[this_shoud_not_have_inside_idx,'is_inside'] = 'NaN'"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Fixed results\n",
                "print('neuron are {}'.format(sum(df_progress.is_neuron=='y')))\n",
                "print('glia are {}'.format(sum(df_progress.is_glia=='y')))\n",
                "print('inside are {}'.format(sum(df_progress.is_inside=='y')))\n",
                "print('outside are {}'.format(sum(df_progress.is_outside=='y')))\n",
                "print('in total {}'.format(len(df_progress)))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df_progress.to_csv('../Output/proofread_soma_temp.csv', index=False) # save into csv"
            ]
        }
    ],
    "metadata": {
        "interpreter": {
            "hash": "3e8f183bd7944e152f2cac16c10b6a857d859db4a3e89a573de1818f219d7cd5"
        },
        "kernelspec": {
            "display_name": "Python 3.9.6 64-bit ('nuclei': venv)",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.9.13 (main, May 24 2022, 21:28:12) \n[Clang 12.0.0 (clang-1200.0.32.29)]"
        },
        "orig_nbformat": 4
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
