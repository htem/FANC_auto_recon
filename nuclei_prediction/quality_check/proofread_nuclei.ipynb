{
    "cells": [
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# proofread_nuclei\n",
                "Here, we first mainly proofread the `'nuc_xyz'` column using Neuroglancer."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import numpy as np\n",
                "import pyperclip\n",
                "import pandas as pd\n",
                "import pyperclip\n",
                "from cloudvolume import CloudVolume, view, Bbox\n",
                "from nglui import statebuilder,annotation,easyviewer,parser\n",
                "from nglui.statebuilder import *\n",
                "from nglui.nglite import *\n",
                "import json\n",
                "import sys\n",
                "import os\n",
                "from datetime import datetime\n",
                "from caveclient import CAVEclient\n",
                "from ..lib import get_cv_path\n",
                "from fanc import rootID_lookup as IDlook"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "datastack_name = 'fanc_production_mar2021'\n",
                "client = CAVEclient(datastack_name)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df = pd.read_csv('../Output/soma_info_Aug2021ver5.csv', header=0)"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Create Neuroglancer links\n",
                "You can create various types of annotation in Neuroglancer. Here, we used a line type and connected `'nuc_xyz'` and `'soma_xyz'` (i.e., 17,076 lines in total), and check each of them. See [this example](https://github.com/seung-lab/NeuroglancerAnnotationUI/blob/master/examples/statebuilder_examples.ipynb) as well."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# we only need xyz for nuclei/somas..., and make them into lines\n",
                "xyz_df = df.reindex(columns=['nuc_xyz', 'soma_xyz'])\n",
                "nuc_xyz_df = df['nuc_xyz'].str.strip('()').str.split(',',expand=True)\n",
                "soma_xyz_df = df['soma_xyz'].str.strip('()').str.split(',',expand=True)\n",
                "xyz_df['nuc_xyz'] = nuc_xyz_df.astype(int).values.tolist()\n",
                "xyz_df['soma_xyz'] = soma_xyz_df.astype(int).values.tolist()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "nuc_xyz_df = nuc_xyz_df.set_axis(['Col_x', 'Col_y', 'Col_z'], axis=1)\n",
                "sorted_z = nuc_xyz_df.astype(int).sort_values(by=['Col_z'], ascending=True)\n",
                "sorted_xz = sorted_z.astype(int).sort_values(by=['Col_x'], ascending=True)\n",
                "sorted_indices = sorted_xz.astype(int).sort_values(by=['Col_y'], ascending=True).index\n",
                "xyz_df = xyz_df.reindex(sorted_indices).reset_index(drop=True)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ..., and make them into lines\n",
                "lines = LineMapper(point_column_a='nuc_xyz', point_column_b='soma_xyz')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# make Neuroglancer link\n",
                "imgTokyo = ImageLayerConfig(name = 'FANCv4-jp',\n",
                "                                    source = get_cv_path('Image_Tokyo')['url'])\n",
                "img = ImageLayerConfig(name = 'FANCv4',\n",
                "                                    source = get_cv_path('Image')['url'])\n",
                "seg = SegmentationLayerConfig(name = 'seg_Mar2021_proofreading',\n",
                "                                    source = get_cv_path('FANC_production_segmentation')['url'])     \n",
                "nuc_Aug = ImageLayerConfig(name = 'nuc',\n",
                "                                    source = get_cv_path('nuclei_map_Aug2021')['url'])      \n",
                "nuc_seg_Aug = ImageLayerConfig(name = 'nuc_seg',\n",
                "                                    source = get_cv_path('nuclei_seg_Aug2021')['url'])        \n",
                "\n",
                "ann = AnnotationLayerConfig(name='nuc_soma_Aug2021',\n",
                "                            mapping_rules=lines,\n",
                "                            tags=['neuron', 'glia','false_positive','soma_need_check'],\n",
                "                            active = True)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "view_options = {\"layout\": \"xy\"}\n",
                "\n",
                "memory_options = {\"gpuMemoryLimit\": 4000000000,\n",
                "                  \"systemMemoryLimit\": 8000000000,\n",
                "                  \"concurrentDownloads\": 64,\n",
                "                  \"jsonStateServer\": \"https://global.daf-apis.com/nglstate/api/v1/post\"}\n",
                "\n",
                "\n",
                "sb = StateBuilder(layers=[imgTokyo, seg, img, nuc_Aug, nuc_seg_Aug, ann],\n",
                "                  resolution=[4.3,4.3,45],\n",
                "                  view_kws=view_options)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "LINK=[]\n",
                "k=500\n",
                "minidfs = [xyz_df.loc[i:i+k-1, :] for i in range(0, len(xyz_df), k)]\n",
                "for dftmp in minidfs:\n",
                "    # csb = ChainedStateBuilder([sb, vs])                             \n",
                "    state = json.loads(sb.render_state(dftmp, return_as='json'))\n",
                "    state.update(memory_options)\n",
                "    jsn_id = client.state.upload_state_json(state)\n",
                "    output = client.state.build_neuroglancer_url(jsn_id, get_cv_path('neuroglancer_base')['url'])\n",
                "    # output =get_cv_path('neuroglancer_base')['url'] + '?json_url={path}{state_id}'.format(path=get_cv_path('json_server')['url'],state_id=client.state.upload_state_json(state))\n",
                "    LINK.append(output)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# save into csv\n",
                "LINK2 = pd.DataFrame(LINK)\n",
                "LINK2.to_csv('../Output/links_20210903.csv', index=False, header=False)\n",
                "# Import this csv file on GoogleSheet, Excel, etc...\n",
                "# Each link only has 500 lines (nuclei). When you have finished proofreading, create a new json state and save in the 'new link' column\n",
                "# If you are not sure, just skip it. We can comeback later."
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Extract tags from proofreading results and save those done\n",
                "After you (roughly) checked each nucleus, save the progress in a csv file. Here, we use function from [this svript](https://github.com/seung-lab/NeuroglancerAnnotationUI/blob/36f03cab5ccff8c52b0faba8beff7ab77398ef48/src/nglui/parser/base.py)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# run this when you are proofreading for the first time\n",
                "\n",
                "# df['is_neuron']=\"\"\n",
                "# df['is_glia']=\"\"\n",
                "# df['is_false_positive']=\"\"\n",
                "# df['is_duplicated']=\"\"\n",
                "# df.to_csv('../Output/proofread_nuc_temp.csv', index=False)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df_progress = pd.read_csv(\"../Output/proofread_nuc_temp.csv\", header=0)\n",
                "prfrd1 = pd.read_table(\"../Output/final_proofreading.tsv\", usecols = ['new link'])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "rsplitted = prfrd1['new link'].dropna(how='all').str.rsplit('/', 1)\n",
                "new_id = list()\n",
                "for i in rsplitted.index:\n",
                "    new_id.append(rsplitted.loc[i][1])\n",
                "\n",
                "print(len(new_id))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "mylist = []\n",
                "\n",
                "for i in range(len(new_id)):\n",
                "    state_id = int(new_id[i])\n",
                "    state = client.state.get_state_json(state_id)\n",
                "\n",
                "    # extract info from json state\n",
                "    nuc_tags = parser.tag_dictionary(state,parser.annotation_layers(state)[0])\n",
                "    anno_lists = parser.line_annotations(state,parser.annotation_layers(state)[0], tags=True)\n",
                "\n",
                "    temp = pd.DataFrame({'anno_points_A': anno_lists[0],\n",
                "                     'anno_points_B': anno_lists[1],\n",
                "                     'anno_tags': anno_lists[2]})\n",
                "\n",
                "    # convert [] to [0]\n",
                "    for j in range(len(temp)):\n",
                "        if (len(temp.iloc[j,2]) == 0) or (len(temp.iloc[j,2]) >= 2): # make dup to 0 for now....\n",
                "            temp.iloc[j,2] = [0]\n",
                "            # temp['anno_tags']\n",
                "\n",
                "    temp['anno_tags'] = np.concatenate(temp['anno_tags']).astype(int)\n",
                "    temp['anno_tags'] = temp['anno_tags'].replace(nuc_tags)\n",
                "\n",
                "    mylist.append(temp)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df_new = pd.concat(mylist).reset_index()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print('neuron are {}'.format(sum(df_new['anno_tags']=='neuron')))\n",
                "print('glia are {}'.format(sum(df_new['anno_tags']=='glia')))\n",
                "print('false_positive are {}'.format(sum(df_new['anno_tags']=='false_positive')))\n",
                "print('come_back_to_me_later are {}'.format(sum(df_new['anno_tags']==0)))\n",
                "print('in total {}'.format(len(df_new)))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df_new.drop(\"index\", axis=1).to_csv('../Output/final_proofread_extracted.csv', index=False) # progress saved"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Make new links for those not proofread yet (and repeat this process)\n",
                "Some nuclei are not proofread yet, so we made another csv file with links (and repeat this process until there are no nuclei left.)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df_new2 = df_new[df_new['anno_tags']=='0']\n",
                "print(len(df_new2))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "xyz_df = df_new2.reindex(columns=['anno_points_A', 'anno_points_B']).reset_index()\n",
                "nuc_xyz_df = df_new2['anno_points_A'].str.strip('[]').str.split(',',expand=True)\n",
                "soma_xyz_df = df_new2['anno_points_B'].str.strip('[]').str.split(',',expand=True)\n",
                "xyz_df['anno_points_A'] = nuc_xyz_df.astype(int).values.tolist()\n",
                "xyz_df['anno_points_B'] = soma_xyz_df.astype(int).values.tolist()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "lines = LineMapper(point_column_a='anno_points_A', point_column_b='anno_points_B')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# make Neuroglancer link\n",
                "imgTokyo = ImageLayerConfig(name = 'FANCv4-jp',\n",
                "                                    source = get_cv_path('Image_Tokyo')['url'])\n",
                "img = ImageLayerConfig(name = 'FANCv4',\n",
                "                                    source = get_cv_path('Image')['url'])\n",
                "seg = SegmentationLayerConfig(name = 'seg_Mar2021_proofreading',\n",
                "                                    source = get_cv_path('FANC_production_segmentation')['url'])     \n",
                "nuc_Aug = ImageLayerConfig(name = 'nuc',\n",
                "                                    source = get_cv_path('nuclei_map_Aug2021')['url'])      \n",
                "nuc_seg_Aug = ImageLayerConfig(name = 'nuc_seg',\n",
                "                                    source = get_cv_path('nuclei_seg_Aug2021')['url'])        \n",
                "\n",
                "ann = AnnotationLayerConfig(name='nuc_soma_Aug2021',\n",
                "                            mapping_rules=lines,\n",
                "                            tags=['neuron', 'glia','false_positive','soma_need_check'],\n",
                "                            active = True)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "view_options = {\"layout\": \"xy\"}\n",
                "\n",
                "memory_options = {\"gpuMemoryLimit\": 4000000000,\n",
                "                  \"systemMemoryLimit\": 8000000000,\n",
                "                  \"concurrentDownloads\": 64,\n",
                "                  \"jsonStateServer\": \"https://global.daf-apis.com/nglstate/api/v1/post\"}\n",
                "\n",
                "\n",
                "sb = StateBuilder(layers=[imgTokyo, seg, img, nuc_Aug, nuc_seg_Aug, ann],\n",
                "                  resolution=[4.3,4.3,45],\n",
                "                  view_kws=view_options)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "LINK=[]\n",
                "k=500\n",
                "minidfs = [xyz_df.loc[i:i+k-1, :] for i in range(0, len(xyz_df), k)]\n",
                "for dftmp in minidfs:\n",
                "    # csb = ChainedStateBuilder([sb, vs])                             \n",
                "    state = json.loads(sb.render_state(dftmp, return_as='json'))\n",
                "    state.update(memory_options)\n",
                "    jsn_id = client.state.upload_state_json(state)\n",
                "    output = client.state.build_neuroglancer_url(jsn_id, get_cv_path('neuroglancer_base')['url'])\n",
                "    LINK.append(output)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# save into csv\n",
                "LINK2 = pd.DataFrame(LINK)\n",
                "LINK2.to_csv('../Output/links_20210928-2.csv', index=False, header=False)"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## X. Save final results\n",
                "When you proofread all the nuclei, run the cells below to save all of your efforts into one single file."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df_new = pd.read_csv(\"../Output/final_proofread_extracted.csv\", header=0)\n",
                "df_progress = pd.read_csv(\"../Output/proofread_nuc_temp.csv\", header=0)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df_new2 = df_new[df_new.anno_tags != '0']"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "for i in range(len(df_new2)):\n",
                "    nuc_loc_temp = df_new2['anno_points_A'].values[i].strip('[]')\n",
                "    nuc_loc = '(' + nuc_loc_temp + ')'\n",
                "    nuc_tag = df_new2['anno_tags'].values[i]\n",
                "    if nuc_loc in df_progress['nuc_xyz'].values:\n",
                "        idx = df_progress.index[df_progress['nuc_xyz'] == nuc_loc]\n",
                "        if nuc_tag == 'neuron':\n",
                "            df_progress.at[idx,'is_neuron'] = 'y'\n",
                "        if nuc_tag == 'glia':\n",
                "            df_progress.at[idx,'is_glia'] = 'y'\n",
                "        if nuc_tag == 'false_positive':\n",
                "            df_progress.at[idx,'is_false_positive'] = 'y'"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df_come_back_to_me_later = df_progress[~(df_progress.is_neuron=='y') & ~(df_progress.is_glia=='y') & ~(df_progress.is_false_positive=='y')]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print('neuron are {}'.format(sum(df_progress.is_neuron=='y')))\n",
                "print('glia are {}'.format(sum(df_progress.is_glia=='y')))\n",
                "print('false_positive are {}'.format(sum(df_progress.is_false_positive=='y')))\n",
                "print('come_back_to_me_later are {}'.format(len(df_come_back_to_me_later)))\n",
                "print('in total {}'.format(len(df_progress)))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df_progress.to_csv('../Output/proofread_nuc_temp.csv', index=False) # this final output of 1st quality check"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "nuclei",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.9.13"
        },
        "orig_nbformat": 4,
        "vscode": {
            "interpreter": {
                "hash": "3e8f183bd7944e152f2cac16c10b6a857d859db4a3e89a573de1818f219d7cd5"
            }
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
