{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Predict parent neuron\n",
    "Using Jasper's idea to predict parent neurons for nuclei, Thank you so much, Jasper."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "# libraries 1\n",
    "import numpy as np\n",
    "import pyperclip\n",
    "import pandas as pd\n",
    "import pyperclip\n",
    "from cloudvolume import CloudVolume, view, Bbox\n",
    "from nglui import statebuilder,annotation,easyviewer,parser\n",
    "from nglui.statebuilder import *\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import argparse\n",
    "\n",
    "from PIL import Image\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import os\n",
    "import csv\n",
    "from datetime import datetime\n",
    "\n",
    "from tifffile.tifffile import imwrite\n",
    "\n",
    "sys.path.append(os.path.abspath(\"../segmentation\"))\n",
    "import authentication_utils as auth\n",
    "import rootID_lookup as IDlook\n",
    "sys.path.append(os.path.abspath(\"../synapses\"))\n",
    "import connectivity_utils\n",
    "\n",
    "%matplotlib inline"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "np.random.seed(123)\n",
    "# read csv file\n",
    "df = pd.read_csv('../Output/body_info_Aug2021.csv', header=0)\n",
    "len(df)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "17076"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# A. Create Neuroglancer links for Nucleus Proofreading\n",
    "based on https://github.com/bjm5164/rotation_projects/blob/main/statebuilder_examples.ipynb"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# color_column not supported for point annotation\n",
    "imgTokyo = ImageLayerConfig(name = 'FANC_EM_Tokyo',\n",
    "                                    source = auth.get_cv_path('Image_Tokyo')['url'])\n",
    "img = ImageLayerConfig(name = 'FANC_EM',\n",
    "                                    source = auth.get_cv_path('Image')['url'])\n",
    "nuc_Aug = ImageLayerConfig(name = 'nuclei_Aug2021',\n",
    "                                    source = auth.get_cv_path('nuclei_map_Aug2021')['url'])      \n",
    "nuc_seg_Aug = ImageLayerConfig(name = 'nuclei_Aug2021_seg',\n",
    "                                    source = auth.get_cv_path('nuclei_seg_Aug2021')['url'])      \n",
    "nuc_Jul = ImageLayerConfig(name = 'nuclei_Jul2021',\n",
    "                                    source = auth.get_cv_path('nuclei_map_Jul2021')['url'])      \n",
    "nuc_seg_Jul = ImageLayerConfig(name = 'nuclei_Jul2021_seg',\n",
    "                                    source = auth.get_cv_path('nuclei_seg_Jul2021')['url'])   \n",
    "seg = SegmentationLayerConfig(name = 'FANC_production_segmentation',\n",
    "                                    # selected_ids_column='nuc_segID',\n",
    "                                    source = auth.get_cv_path('FANC_production_segmentation')['url'])      \n",
    "\n",
    "\n",
    "df2 = df.assign(pt_position=[*zip(df.x, df.y, df.z)])\n",
    "points = PointMapper(point_column='pt_position')\n",
    "ann = AnnotationLayerConfig(name='nuc_center_Aug', mapping_rules=points, color='#32CB42',active = True,)      \n",
    "sb = StateBuilder(layers=[imgTokyo, seg, img, nuc_Aug, nuc_seg_Aug, nuc_Jul, nuc_seg_Jul, ann],resolution=[4.3,4.3,45]) # view_kws=view_options\n",
    "\n",
    "client,token = auth.get_client()\n",
    "\n",
    "state = json.loads(sb.render_state(df2, return_as='json'))\n",
    "\n",
    "out =auth.get_cv_path('neuroglancer_base')['url'] + '?json_url={path}{state_id}'.format(path=auth.get_cv_path('json_server')['url'],state_id=client.state.upload_state_json(state))\n",
    "out\n",
    "# https://neuromancer-seung-import.appspot.com/?json_url=https://api.zetta.ai/json/692331708447824330\n",
    "# https://github.com/htem/FANC_auto_recon/blob/main/proofreading/proofreading_utils.py\n",
    "\n",
    "\n",
    "\n",
    "LINK=[]\n",
    "k=200\n",
    "minidfs = [df.loc[i:i+k-1, :] for i in range(0, len(df), k)]\n",
    "for dftemp in minidfs:\n",
    "    seg = SegmentationLayerConfig(name = 'FANC_production_segmentation',\n",
    "                                        # selected_ids_column='nuc_segID',\n",
    "                                        source = auth.get_cv_path('FANC_production_segmentation')['url'])                                 \n",
    "    sb = StateBuilder(layers=[imgTokyo, seg, img, nuc, nuc_seg],resolution=[4.3,4.3,45]) # view_kws=view_options\n",
    "    output = sb.render_state(dftemp) #return_as='html'\n",
    "    LINK.append(output)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# https://api.zetta.ai/json/post"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# save into csv\n",
    "LINK2 = pd.DataFrame(LINK)\n",
    "LINK2.to_csv('../Output/nuc_links.csv', index=False, header=False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# B. Test my soma list with other table"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# T1MN_somas test\n",
    "MNsomas = pd.read_csv('../Output/T1MN_somas.csv', header=0)\n",
    "MNsomas['pt_root_id'].values\n",
    "\n",
    "exist = []\n",
    "no_exist = []\n",
    "for i in MNsomas['pt_root_id'].values:\n",
    "    if i in df['body_segID'].values:\n",
    "        exist.append(i)\n",
    "    else:\n",
    "        no_exist.append(i)\n",
    "\n",
    "print(no_exist)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "check = 648518346486520985\n",
    "print (MNsomas.loc[MNsomas['pt_root_id'] == check])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "nuc = 648518346481315476\n",
    "df[df['nuc_segID']==nuc]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# C. Summarize count data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "count = pd.read_csv('../Output/ncount_merged.csv', header=None)\n",
    "count2 = count.T.dropna()\n",
    "# len(count2) \n",
    "# 15094\n",
    "count3 = count2.sort_values(by=0)\n",
    "count4 = count3.astype('int')\n",
    "count4.columns = ['index', 'count']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "sv_size_thres=4000\n",
    "chosen = count4.loc[count4['count'] <= sv_size_thres]\n",
    "chosen['index'].values"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "test = df.loc[chosen['index'].values]\n",
    "test[0:999]\n",
    "rantest = test.iloc[np.random.choice(len(test), round(len(test)/5), replace=False)]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# nuclei itself\n",
    "imgTokyo = ImageLayerConfig(name = 'FANC_EM_Tokyo',\n",
    "                                    source = auth.get_cv_path('Image_Tokyo')['url'])\n",
    "img = ImageLayerConfig(name = 'FANC_EM',\n",
    "                                    source = auth.get_cv_path('Image')['url'])\n",
    "nuc = ImageLayerConfig(name = 'nuclei(old)',\n",
    "                                    source = auth.get_cv_path('nuclei_map')['url'])                                    \n",
    "# volume = SegmentationLayerConfig(name = 'volume_outlines',\n",
    "#                                    source = auth.get_cv_path('Image')['url'])   \n",
    "\n",
    "seg = SegmentationLayerConfig(name = 'FANC_production_segmentation',\n",
    "                                        active = True,\n",
    "                                        source = auth.get_cv_path('FANC_production_segmentation')['url'],\n",
    "                                        selected_ids_column='segIDs')                                 \n",
    "sb = StateBuilder(layers=[imgTokyo, seg, nuc, img],resolution=[4.3,4.3,45]) # view_kws=view_options\n",
    "output = sb.render_state(rantest, return_as='html')\n",
    "output"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "sv_size_thres=4000\n",
    "notchosen = count4.loc[count4['count'] > sv_size_thres+2000]\n",
    "test2 = df.loc[notchosen['index'].values]\n",
    "test2"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "rantest2 = test2.iloc[np.random.choice(len(test2), round(len(test2)/5), replace=False)]\n",
    "output = sb.render_state(rantest2, return_as='html')\n",
    "output"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# D. Get premotor inputs"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# get premotor inputs\n",
    "MN = pd.read_csv('../Output/MNs.csv', header=0)\n",
    "MN"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# E. point map"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# color_column not supported for point annotation\n",
    "imgTokyo = ImageLayerConfig(name = 'FANC_EM_Tokyo',\n",
    "                                    source = auth.get_cv_path('Image_Tokyo')['url'])\n",
    "img = ImageLayerConfig(name = 'FANC_EM',\n",
    "                                    source = auth.get_cv_path('Image')['url'])\n",
    "nuc_Aug = ImageLayerConfig(name = 'nuclei_Aug2021',\n",
    "                                    source = auth.get_cv_path('nuclei_map_Aug2021')['url'])      \n",
    "nuc_seg_Aug = ImageLayerConfig(name = 'nuclei_Aug2021_seg',\n",
    "                                    source = auth.get_cv_path('nuclei_seg_Aug2021')['url'])      \n",
    "nuc_Jul = ImageLayerConfig(name = 'nuclei_Jul2021',\n",
    "                                    source = auth.get_cv_path('nuclei_map_Jul2021')['url'])      \n",
    "nuc_seg_Jul = ImageLayerConfig(name = 'nuclei_Jul2021_seg',\n",
    "                                    source = auth.get_cv_path('nuclei_seg_Jul2021')['url'])   \n",
    "# volume = SegmentationLayerConfig(name = 'volume_outlines',\n",
    "#                                    source = auth.get_cv_path('Image')['url'])   \n",
    "\n",
    "seg = SegmentationLayerConfig(name = 'FANC_production_segmentation',\n",
    "                                    active = True,\n",
    "                                    source = auth.get_cv_path('FANC_production_segmentation')['url'])\n",
    "\n",
    "df2 = df.assign(pt_position=[*zip(df.x, df.y, df.z)])\n",
    "points = PointMapper(point_column='pt_position')\n",
    "ann = AnnotationLayerConfig(name='nuc_center_Aug', mapping_rules=points, color='#32CB42')      \n",
    "sb = StateBuilder(layers=[imgTokyo, seg, img, nuc_Aug, nuc_seg_Aug, nuc_Jul, nuc_seg_Jul, ann],resolution=[4.3,4.3,45]) # view_kws=view_options\n",
    "\n",
    "client,token = auth.get_client()\n",
    "\n",
    "state = json.loads(sb.render_state(df2, return_as='json'))\n",
    "\n",
    "out =auth.get_cv_path('neuroglancer_base')['url'] + '?json_url={path}{state_id}'.format(path=auth.get_cv_path('json_server')['url'],state_id=client.state.upload_state_json(state))\n",
    "out\n",
    "# https://neuromancer-seung-import.appspot.com/?json_url=https://api.zetta.ai/json/692331708447824330\n",
    "# https://github.com/htem/FANC_auto_recon/blob/main/proofreading/proofreading_utils.py"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# https://api.zetta.ai/json/post"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# F. Descending and Ascending neurons"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# read data\n",
    "left_d = np.fromfile('../Output/da/left_d.bin', dtype=np.int64)\n",
    "left_a = np.fromfile('../Output/da/left_a.bin', dtype=np.int64)\n",
    "right_d = np.fromfile('../Output/da/right_d.bin', dtype=np.int64)\n",
    "right_a = np.fromfile('../Output/da/right_a.bin', dtype=np.int64)\n",
    "\n",
    "pMN_T1L = pd.read_csv('../Output/da/pMN_T1L.csv', header=0)\n",
    "pMN_T1R = pd.read_csv('../Output/da/pMN_T1R.csv', header=0)\n",
    "\n",
    "left_dout = pd.read_csv('../Output/da/left_dout.csv', header=0)\n",
    "left_aout = pd.read_csv('../Output/da/left_aout.csv', header=0)\n",
    "right_dout = pd.read_csv('../Output/da/right_dout.csv', header=0)\n",
    "right_aout = pd.read_csv('../Output/da/right_aout.csv', header=0)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_temp = pd.concat([pMN_T1L, pMN_T1R], axis=0)\n",
    "aggregation_functions = {'synapses': 'sum'}\n",
    "pMN_T1all = df_temp.groupby(df_temp['root_id']).aggregate(aggregation_functions)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def find_T1input(array, threshold=3):\n",
    "    left = array[np.isin(array, pMN_T1L[pMN_T1L['synapses'] >= threshold]['root_id'].values)]\n",
    "    right = array[np.isin(array, pMN_T1R[pMN_T1R['synapses'] >= threshold]['root_id'].values)]\n",
    "    both = np.intersect1d(left, right)\n",
    "    others = array[np.isin(array,np.unique(np.concatenate((left, right))), invert=True)]\n",
    "\n",
    "    return np.array([len(both), len(left), len(right), len(others)])/len(array), np.array([len(both), len(left), len(right), len(others)]), both\n",
    "\n",
    "def find_DANoutput(array, threshold=3):\n",
    "    left_d = array[np.isin(array, left_dout[left_dout['synapses'] >= threshold]['root_id'].values)]\n",
    "    left_a = array[np.isin(array, left_aout[left_aout['synapses'] >= threshold]['root_id'].values)]\n",
    "    right_d = array[np.isin(array, right_dout[right_dout['synapses'] >= threshold]['root_id'].values)]\n",
    "    right_a = array[np.isin(array, right_aout[right_aout['synapses'] >= threshold]['root_id'].values)]\n",
    "    both_left = np.intersect1d(left_d, left_a)\n",
    "    both_right = np.intersect1d(right_d, right_a)\n",
    "    both_d = np.intersect1d(left_d, right_d)\n",
    "    both_a = np.intersect1d(left_a, right_a)\n",
    "    all = np.intersect1d(left_d, left_a, right_d, right_a)\n",
    "    others = array[np.isin(array,np.unique(np.concatenate((left_d, left_a, right_d, right_a))), invert=True)]\n",
    "\n",
    "    return np.array([len(all), len(both_a), len(both_d), len(both_left), len(both_right), len(left_d), len(left_a), len(right_d), len(right_a), len(others)])/len(array), np.array([len(all), len(both_a), len(both_d), len(both_left), len(both_right), len(left_d), len(left_a), len(right_d), len(right_a), len(others)])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Do Descending and Ascending neurons project into MNs? If they do, how many of them?\n",
    "# Left descending\n",
    "Ld, Ld_abs, Ldboth = find_T1input(left_d, threshold=10)\n",
    "La, La_abs, Laboth = find_T1input(left_a, threshold=10)\n",
    "Rd, Rd_abs, Rdboth = find_T1input(right_d, threshold=10)\n",
    "Ra, Ra_abs, Raboth = find_T1input(right_a, threshold=10)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Laboth\n",
    "# https://neuromancer-seung-import.appspot.com/?json_url=https://global.daf-apis.com/nglstate/api/v1/4598740472037376"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "g = pd.DataFrame(data=np.vstack([Ld, La, Rd, Ra]),\n",
    "                                index=['Left descending', 'Left ascending', 'Right descending', 'Right ascending'],\n",
    "                                columns=['T1L & T1R', 'T1L', 'T1R', 'others'])\n",
    "plt.figure()\n",
    "sns.heatmap(g, annot=np.vstack([Ld_abs, La_abs, Rd_abs, Ra_abs]), fmt='d')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Then how many MNs receive inputs from Descending and Ascending?\n",
    "MN = pd.read_csv('../Output/da/MN.csv', header=0)\n",
    "\n",
    "T1L, T1L_abs = find_DANoutput(MN[MN['name'].str.endswith('T1L')]['pt_root_id'].values, threshold=3)\n",
    "T1R, T1R_abs = find_DANoutput(MN[MN['name'].str.endswith('T1R')]['pt_root_id'].values, threshold=3)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "g = pd.DataFrame(data=np.vstack([T1L, T1R]),\n",
    "                                index=['T1L', 'T1R'],\n",
    "                                columns=['all', 'AN', 'DN', 'left', 'right', 'leftDN', 'leftAN', 'rightDN', 'rightAN', 'others'])\n",
    "plt.figure()\n",
    "sns.heatmap(g, annot=np.vstack([T1L_abs, T1R_abs]), fmt='d')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "MNinputs = pd.read_csv('../Output/da/MNinputs.csv', header=0, index_col=0)\n",
    "DANoutputs = pd.read_csv('../Output/da/DANoutputs.csv', header=0, index_col=0)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# check"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# T1L\n",
    "test = MNinputs.loc[MNinputs.index.isin(MN[MN['name'].str.endswith('T1R')]['pt_root_id'].values),]\n",
    "test = test.sum() # sum\n",
    "test2 = test.drop([\"648518346485926546.1\", '648518346499332071.1','648518346502185555.1','648518346494092402.1','648518346481307329.1',\"others\"], axis=0)\n",
    "test2 = test2[test2>=10] # more than 10 synapses\n",
    "\n",
    "A = np.isin(test2.index.values.astype(int), right_d)\n",
    "sum(A)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "test2"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# left_d\n",
    "test = DANoutputs.loc[DANoutputs.index.isin(left_d),]\n",
    "test = test.sum() # sum\n",
    "test2 = test.drop([\"648518346490791971.1\", \"others\"], axis=0)\n",
    "test2 = test2[test2>=10] # more than 10 synapses"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "A"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# G. Update soma table"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "MN = pd.read_csv('../Output/da/MN.csv', header=0)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "date = '2021-06-07 00:00' # UTC\n",
    "if date != None:\n",
    "    dt_date = datetime.strptime(date, '%Y-%m-%d %H:%M')\n",
    "    timestamp = int(dt_date.timestamp())\n",
    "else:\n",
    "    timestamp = None"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "MNnew = MN.copy()\n",
    "cv = auth.get_cv()\n",
    "xyz = MNnew['pt_position'].str.strip('[]').str.split(',',expand=True)\n",
    "MNnew['pt_root_id'] = IDlook.segIDs_from_pts_cv(xyz.astype(int).to_numpy(),cv, timestamp=timestamp)"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "HTTPError",
     "evalue": "401 Client Error: UNAUTHORIZED for url: https://cave.fanc-fly.com/segmentation/table/mar2021_prod/info",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1138/3075151798.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mMNnew\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mauth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_cv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mxyz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMNnew\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pt_position'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'[]'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mexpand\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mMNnew\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pt_root_id'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mIDlook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msegIDs_from_pts_cv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxyz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/workspaces/FANC_auto_recon/segmentation/authentication_utils.py\u001b[0m in \u001b[0;36mget_cv\u001b[0;34m(segmentation, use_https, agglomerate)\u001b[0m\n\u001b[1;32m     99\u001b[0m            agglomerate=False):\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mCloudVolume\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_cv_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msegmentation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'url'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0muse_https\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0magglomerate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0magglomerate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/pip-global/cloudvolume/cloudvolume.py\u001b[0m in \u001b[0;36m__new__\u001b[0;34m(cls, cloudpath, mip, bounded, autocrop, fill_missing, cache, compress_cache, cdn_cache, progress, info, provenance, compress, compress_level, non_aligned_writes, parallel, delete_black_uploads, background_color, green_threads, use_https, max_redirects, mesh_dir, skel_dir, agglomerate, secrets)\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstrict_extract\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcloudpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mREGISTERED_PLUGINS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 207\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mREGISTERED_PLUGINS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    208\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m       raise UnsupportedFormatError(\n",
      "\u001b[0;32m/usr/local/pip-global/cloudvolume/datasource/graphene/__init__.py\u001b[0m in \u001b[0;36mcreate_graphene\u001b[0;34m(cloudpath, mip, bounded, autocrop, fill_missing, cache, compress_cache, cdn_cache, progress, info, provenance, compress, parallel, delete_black_uploads, background_color, green_threads, use_https, mesh_dir, skel_dir, agglomerate, secrets, **kwargs)\u001b[0m\n\u001b[1;32m     45\u001b[0m       \u001b[0minfo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprovenance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprovenance\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m       \u001b[0muse_https\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_https\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0magglomerate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0magglomerate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m       \u001b[0mauth_token\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msecrets\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m     )\n\u001b[1;32m     49\u001b[0m     \u001b[0;31m# Resetting the cache is necessary because\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/pip-global/cloudvolume/datasource/graphene/metadata.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, cloudpath, use_https, use_auth, auth_token, agglomerate, *args, **kwargs)\u001b[0m\n\u001b[1;32m     93\u001b[0m       }\n\u001b[1;32m     94\u001b[0m     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'use_https'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muse_https\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m     \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGrapheneMetadata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcloudpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[0mversion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserver_path\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/pip-global/cloudvolume/datasource/precomputed/metadata.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, cloudpath, config, cache, info, provenance, max_redirects, use_https)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrefresh_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_redirects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_redirects\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menabled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_info_validity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/pip-global/cloudvolume/datasource/precomputed/metadata.py\u001b[0m in \u001b[0;36mrefresh_info\u001b[0;34m(self, max_redirects, force_fetch)\u001b[0m\n\u001b[1;32m    170\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mredirectable_fetch_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_redirects\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/pip-global/cloudvolume/datasource/precomputed/metadata.py\u001b[0m in \u001b[0;36mredirectable_fetch_info\u001b[0;34m(self, max_redirects)\u001b[0m\n\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_redirects\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 233\u001b[0;31m       \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'redirect'\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'redirect'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/pip-global/cloudvolume/datasource/graphene/metadata.py\u001b[0m in \u001b[0;36mfetch_info\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    157\u001b[0m     \"\"\"\n\u001b[1;32m    158\u001b[0m     \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauth_header\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 159\u001b[0;31m     \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    160\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/pip-global/requests/models.py\u001b[0m in \u001b[0;36mraise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    941\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    942\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 943\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    945\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mHTTPError\u001b[0m: 401 Client Error: UNAUTHORIZED for url: https://cave.fanc-fly.com/segmentation/table/mar2021_prod/info"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "min(MNnew['pt_root_id']/MN['pt_root_id'])"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "MNnew.to_csv('../Output/MNnew.csv', index=False)"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c3593f56db3fdc375a231e1c1fb5fc1dbab03dc3894478fa0aaa4bb9b486beca"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.11 64-bit ('nuclei': venv)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}